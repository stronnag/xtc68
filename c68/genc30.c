/*
 * C compiler
 * ==========
 *
 * Copyright 1989, 1990, 1991 Christoph van Wuellen.
 * Credits to Matthew Brandt.
 * All commercial rights reserved.
 *
 * This compiler may be redistributed as long there is no
 * commercial interest. The compiler must not be redistributed
 * without its full sources. This notice must stay intact.
 *
 * History:
 *
 * 1989   starting an 68000 C compiler, starting with material
 *        originally by M. Brandt
 * 1990   68000 C compiler further bug fixes
 *        started i386 port (December)
 * 1991   i386 port finished (January)
 *        further corrections in the front end and in the 68000
 *        code generator.
 *        The next port will be a SPARC port
 *
 *
 * 1995   Ivo Oesch, Started in to write a codegenerator for the
 *        signalprocessor TMS320C30 (December)
 */

/******************************************************************************
 *
 * this module contains all of the code generation routines for evaluating
 * expressions and conditions.
 *
 *****************************************************************************/

#include "config.h"

#ifdef TMS320C30

#define GEN_MODULE
#include "chdr.h"
#include "expr.h"
#include "cglbdec.h"
#include "proto.h"
#include "genc30.h"
#include "outproto.h"

/********************************************************* Macro Definitions */

#define NEW_BITFIELDSTUFF

#define best_flags(requested, possible) ((FLAGS)((requested & possible) != 0 ? requested & possible : possible))
#define isanyreg(AP) ((AP->mode == am_areg) || (AP->mode == am_dreg) || (AP->mode == am_ireg) || (AP->mode == am_sreg))
#define AL_DEFAULT (g_alignments[bt_ellipsis])
#define is_op3_violated(ap)                                                                                                    \
  (((ap)->mode == am_ainc) || ((ap)->mode == am_adec) || ((ap)->mode == am_preinc) || ((ap)->mode == am_predec) ||             \
   ((ap)->mode == am_direct) || ((ap)->mode == am_immed) || ((ap)->mode == am_const_direct))

/********************************************************** Type Definitions */

typedef struct _itree {
  LABEL label;
  EXPR *value;
  struct _itree *less;
  struct _itree *more;
} ITREE;

/********************************************************** Static Variables */

static SETVAL peep_option = PEEP_STANDARD; /* peehole optimisations */
static int regs_used = 0;                  /* number of register variable allocated */
static int address_reg_used = 0;           /* number of register variable allocated to addressregisters */

static REGMASK restore_mask;                    /* register restore mask */
static REGMASK floatrestore_mask;               /* register restore mask */
static REGMASK interrupt_restore_mask = 0;      /* register restore mask */
static REGMASK interrupt_floatrestore_mask = 0; /* register restore mask */
static REGMASK return_register_mask = 0;        /* used returnregister */
static SIZE max_stack_adjust = 0L;              /* largest amount stack is altered */

static REGMASK forced_save_mask = 0;

#if 0
static REGMASK forced_floatsave_mask = 0;

#else
#define forced_floatsave_mask (forced_save_mask & MASK_REG_DATA)
#endif
/*
 *  The following tables specify the alignment requirements of the
 *  basic types depending on the processor type.
 */
static SIZE alignments_c30[] = {
    1L, /* bt_void      */
    1L, /* bt_char      */
    1L, /* bt_charu     */
    1L, /* bt_uchar     */
    1L, /* bt_schar     */
    1L, /* bt_short     */
    1L, /* bt_ushort    */
    1L, /* bt_int16     */
    1L, /* bt_uint16    */
    1L, /* bt_int32     */
    1L, /* bt_uint32    */
    1L, /* bt_long      */
    1L, /* bt_ulong     */
    1L, /* bt_float     */
    1L, /* bt_double    */
    1L, /* bt_longdouble */
    1L, /* bt_pointer16 */
    1L, /* bt_pointer32 */
    1L, /* bt_struct    */
    1L, /* bt_union     */
    1L, /* bt_func      */
    1L, /* bt_bitfield  */
    1L, /* bt_ubitfield */
    1L  /* bt_ellipsis - used for alignment suitable for all types */
};

/*
 * support routines, define as pointers to be sure to have only
 * one copy in memory of them, else symsearch does not work
 * properly sinc it compares pointers and not contents of strings
 */

static const CHAR *psup_fpdiv = SUP_FPDIV;
static const CHAR *psup_fprem = SUP_FPREM;
static const CHAR *psup_ldiv = SUP_LDIV;
static const CHAR *psup_lrem = SUP_LREM;
static const CHAR *psup_uldiv = SUP_ULDIV;
static const CHAR *psup_ulrem = SUP_ULREM;

static int opt_const_in_ram = OPT_NO;
static int opt_true_long = OPT_NO;
static int stackopt_option = OPT_SAFE;
static int opt_shortfloat = 1;
static int interrupt_option = OPT_NO;
static int opt_traps = OPT_NO;

int opt_branches = OPT_LEVEL1;
int opt_delayed_branches = 2;
const CHAR *opt_peep_sequence = (const CHAR *)"";
int opt_register_remap = OPT_YES;
int opt_3op = OPT_NO;
int opt_peep_test = 0;

REG frameptr = FRAMEPTR;

#ifndef MULTIPLE_PROCESSORS
PRIVATE SIZE *g_alignments = &alignments_c30[0];

#endif /* MULTIPLE_PROCESSORS */

/*********************************************** Static Function Definitions */

static ADDRESS *as_fcall P_((const EXPR *, FLAGS, const CHAR *, ITYPE));
static ADDRESS *func_result P_((FLAGS, SIZE, TYP *));
static ADDRESS *g_addsub P_((const EXPR *, FLAGS, OPCODE));
static ADDRESS *g_aincdec P_((const EXPR *, FLAGS, OPCODE));
static ADDRESS *g_asadd P_((const EXPR *, FLAGS, OPCODE));
static ADDRESS *g_asbitfield P_((const EXPR *, FLAGS, OPCODE, int));
static ADDRESS *g_asdiv P_((const EXPR *, FLAGS, BOOL));
static ADDRESS *g_aslogic P_((const EXPR *, FLAGS, OPCODE));
static ADDRESS *g_asmul P_((const EXPR *, FLAGS));
static ADDRESS *g_asshift P_((const EXPR *, FLAGS, OPCODE));
static ADDRESS *g_assign P_((const EXPR *, FLAGS));
static ADDRESS *g_cast P_((ADDRESS *, TYP *, TYP *, FLAGS));
static ADDRESS *g_conditionalload P_((const EXPR *, ADDRESS *, ADDRESS *, ITYPE, FLAGS));
static ADDRESS *g_deref P_((const EXPR *, TYP *, FLAGS));
static ADDRESS *g_div P_((const EXPR *, FLAGS, BOOL));
static ADDRESS *g_expr P_((const EXPR *, FLAGS));
static ADDRESS *g_fcall P_((const EXPR *, FLAGS));
static ADDRESS *g_fderef P_((const EXPR *, FLAGS));
static ADDRESS *g_hook P_((const EXPR *, FLAGS));
static ADDRESS *g_index P_((const EXPR *));
static ADDRESS *g_logic P_((const EXPR *, FLAGS, OPCODE));
static ADDRESS *g_mul P_((const EXPR *, FLAGS));
static ADDRESS *g_shift P_((const EXPR *, FLAGS, OPCODE));
static ADDRESS *g_unary P_((const EXPR *, FLAGS, OPCODE));
static ADDRESS *mk_legal P_((ADDRESS *, FLAGS, ITYPE));
static ADDRESS *mk_ilabel P_((const EXPR *));
static ADDRESS *check_trap P_((const EXPR *));
static ADDRESS *mk_indirect P_((REG, EXPR *));

static BOOL g_compare P_((const EXPR *));
static BOOL tst_iconst P_((const EXPR *));
static EXPR *copy_iexpr P_((const EXPR *));
static SIZE g_parms P_((const EXPR *));
static SIZE push_param P_((const EXPR *));
static void call_library_r0_r1 P_((const CHAR *));
static void g_immed P_((OPCODE, IVAL, ADDRESS *));
static void g_rotate P_((ADDRESS *, int, TYP *, int));
static void g_test P_((const EXPR *));
static void structassign P_((ADDRESS *, ADDRESS *, SIZE));
static void g_truejp P_((const EXPR *, LABEL));
static void g_falsejp P_((const EXPR *, LABEL));
static void allocate_blockrepeat_registers P_((void));

/*********************************************** Global Function Definitions */

#ifdef MULTIPLE_PROCESSORS
PRIVATE BOOL g_is_ascending_stack P_((void));
PRIVATE BOOL g_is_bigendian P_((void));
PRIVATE EXPR *g_transform P_((EXPR *));
PRIVATE void g_allocate P_((CSE *));
PRIVATE void g_auto_align P_((void));
PRIVATE void g_entry P_((SIZE));
PRIVATE void g_epilogue P_((void));
PRIVATE void g_expression P_((const EXPR *));
PRIVATE void g_flush P_((SYM *));
PRIVATE void g_initialize P_((void));
PRIVATE void g_jfalse P_((const EXPR *, LABEL));
PRIVATE void g_jtrue P_((const EXPR *, LABEL));
PRIVATE void g_label P_((LABEL));
PRIVATE void g_return P_((const EXPR *, TYP *));
PRIVATE void g_stack P_((SIZE));
PRIVATE void g_switch_compare P_((const EXPR *, STMT *));
PRIVATE void g_switch_table P_((const EXPR *, struct swtab *, unsigned long, unsigned long));

#endif /* MULTIPLE_PROCESSORS */

/*****************************************************************************/

/*****************************************************************************/

static ADDRESS *mk_amode P1(AMODE, mode) {
  ADDRESS *ap;
  ap = (ADDRESS *)xalloc((size_t)sizeof(ADDRESS));

  ap->mode = mode;
  return ap;
}

static ADDRESS *mk_expr P2(AMODE, mode, EXPR *, ep) {
  ADDRESS *ap;

  ap = mk_amode(mode);
  ap->u.offset = ep;
  return ap;
}

/*
 * make a node to reference a line number.
 */
static ADDRESS *mk_line P1(LINE, i) { return mk_expr(am_line, mk_const((IVAL)i)); }

/*
 * make a node to reference a source line.
 */
static ADDRESS *mk_linetxt P1(const CHAR *, s) {
  EXPR *ep;

  ep = mk_node(en_str, NIL_EXPR, NIL_EXPR, tp_void);
  ep->v.str = s;
  return mk_expr(am_str, ep);
}

/*
 * copy an address mode structure.
 */
ADDRESS *copy_addr P2(ADDRESS *, ap, AMODE, mode) {
  ADDRESS *newap;

  assert(ap);
  newap = (ADDRESS *)xalloc((size_t)sizeof(ADDRESS));

  *newap = *ap;
  newap->mode = mode;
  return newap;
}
/*
 * make a node to reference an signed immediate value i.
 */
static ADDRESS *mk_immed P1(IVAL, i) {
  if ((i <= 32767L) && (i >= -32768L))
    return mk_expr(am_immed, mk_const(i));
  else
    return mk_ilabel(mk_const(i));
}

/*
 * make a node to reference an unsigned immediate value i.
 */
static ADDRESS *mk_uimmed P1(IVAL, i) {
  if (i < 0)
    FATAL((__FILE__, "mk_uimmed", "value is negative %ld", i));
  if (i <= 0xFFFFL)
    return mk_expr(am_immed, mk_const(i));
  else
    return mk_ilabel(mk_const(i));
}

/*
 * construct a reference node for an internal label number.
 */
ADDRESS *mk_label P1(LABEL, lab) { return mk_expr(am_const_direct, mk_lcon(lab)); }

static ADDRESS *mk_Jumplabel P1(LABEL, lab) { return mk_expr(am_immed, mk_lcon(lab)); }

/*
 * generate a direct reference to a string label.
 */
static ADDRESS *mk_strlab P1(const CHAR *, s) {
  EXPR *ep;

  ep = mk_node(en_nacon, NIL_EXPR, NIL_EXPR, tp_void);
  ep->v.str = s;
  return mk_expr(am_immed, ep);
}

/*
 * generate a call to a library routine.
 * it is assumed that lib_name won''t be clobbered
 */
static void call_library_r0_r1 P1(const CHAR *, lib_name) {
  SYM *sp;

  sp = internal_symbol(lib_name, tp_void);

  /* routines are using all temporary-registers, so
   * intrruptroutines must save them
   */

  interrupt_restore_mask |= (1L << REG_R0) | (1L << REG_R1) | (1L << REG_R2) | (1L << REG_AR0) | (1L << REG_AR1);

  interrupt_floatrestore_mask |= (1L << REG_R0) | (1L << REG_R1) | (1L << REG_R2);

  /*
   *  op_xcall is a marker for the peephole-optimizer,
   *  it assumes, that only xcall uses R0 and R1 registers
   *  for parameterpassing.
   *  all other calls are assumed to use stack for
   *  parameterpassing, so values of r0 and r1 (and
   *  all other tempregs) may be invalidated/overwritten
   *  before functionscall.
   */

  g_code(op_xcall, OP_INT, mk_strlab(nameof(sp)), NIL_ADDRESS);
}

/*
 *  make an address reference to a register.
 */
ADDRESS *mk_reg P1(REG, r) {
  ADDRESS *ap;

  switch (r) {
  case REG_R0:
  case REG_R1:
  case REG_R2:
  case REG_R3:
  case REG_R4:
  case REG_R5:
  case REG_R6:
  case REG_R7:
    ap = mk_amode(am_dreg);
    ap->preg = r;
    break;
  case REG_AR0:
  case REG_AR1:
  case REG_AR2:
  case REG_AR3:
  case REG_AR4:
  case REG_AR5:
  case REG_AR6:
  case REG_AR7:
    ap = mk_amode(am_areg);
    ap->preg = r;
    break;
  case REG_IR0:
  case REG_IR1:
    ap = mk_amode(am_ireg);
    ap->preg = r;
    break;
  case REG_DP:
  case REG_BK:
  case REG_SP:
  case REG_ST:
  case REG_IE:
  case REG_IF:
  case REG_IOF:
  case REG_RS:
  case REG_RE:
  case REG_RC:
    ap = mk_amode(am_sreg);
    ap->preg = r;
    break;
  default:
    CANNOT_REACH_HERE();
    ap = NIL_ADDRESS;
  }
  interrupt_restore_mask |= 1L << r;
  return ap;
}

/*
 * make an address reference to a floatregister.
 */
ADDRESS *mk_freg P1(REG, r) {
  ADDRESS *ap;

  assert(r <= REG_R7);
  ap = mk_amode(am_freg);
  ap->preg = r;
  interrupt_restore_mask |= 1L << r;
  interrupt_floatrestore_mask |= 1L << r;
  return ap;
}

/*
 * returns addressing mode of form offset(frameptr)
 * size is rounded up to AL_DEFAULT
 */
static ADDRESS *mk_scratch P1(SIZE, size) {
  ADDRESS *ap;
  SIZE default_alignment = AL_DEFAULT;

  /* round up the request */
  if (size % default_alignment)
    size += default_alignment - (size % default_alignment);

  /* allocate the storage */
  act_scratch += size;

  /*
   * The next statement could be deferred and put into the
   * routine checkstack(), but this is just safer.
   */
  if (act_scratch > max_scratch) {
    max_scratch = act_scratch;
  }
  /* do not add act_scratch, because pointer must point to start of
   * scratch area
   */
  ap = mk_indirect(frameptr, mk_const((lc_auto_max + 1)));
  return ap;
}

/*
 * push all register in the masks onto stack.
 */
static void push_registers P2(REGMASK, mask, REGMASK, floatmask) {
  REG reg;

  for (reg = MAX_REG; reg >= REG_R0; reg--) {
    /* Check which registers are set in mask */
    if ((mask & (1L << reg)) != 0) {
      g_code(op_pushnopeep, OP_INT, mk_reg(reg), NIL_ADDRESS);
    }
    if ((floatmask & (1L << reg)) != 0) {
      g_code(op_pushfnopeep, OP_FLOAT, mk_reg(reg), NIL_ADDRESS);
    }
  }
}

/*
 * pop all registers in the masks from the stack.
 */
static void pop_registers P2(REGMASK, mask, REGMASK, floatmask) {
  REG reg;

  for (reg = REG_R0; reg <= MAX_REG; reg++) {
    /* Check which registers are set in mask */
    if ((floatmask & (1L << reg)) != 0) {
      g_code(op_popf, OP_FLOAT, NIL_ADDRESS, mk_reg(reg));
    }
    if ((mask & (1L << reg)) != 0) {
      g_code(op_pop, OP_INT, NIL_ADDRESS, mk_reg(reg));
    }
  }
}

/*
 * reads all register in the mask from the stack
 * this version does not use pop, but indeed address based on framepointer
 * and offset of the pushed registers from framepointer
 * generates in some cases faster code than poped version
 * since sp must not be set correctly as in the pop-variant
 */
static void pop_fast_registers P3(REGMASK, mask, REGMASK, floatmask, int, offset) {
  REG reg;
  ADDRESS *ap;

  for (reg = REG_R0; reg <= MAX_REG; reg++) {
    /* Check which registers are set in mask */
    if ((floatmask & (1L << reg)) != 0) {
      ap = mk_amode(am_indx);
      ap->preg = frameptr; /* frame pointer */
      ap->u.offset = mk_const(offset--);
      g_code(op_popldf, OP_FLOAT, ap, mk_reg(reg));
    }
    if ((mask & (1L << reg)) != 0) {
      ap = mk_amode(am_indx);
      ap->preg = frameptr; /* frame pointer */
      ap->u.offset = mk_const(offset--);
      g_code(op_popldi, OP_INT, ap, mk_reg(reg));
    }
  }
}

/*
 * make a direct reference to a node.
 */
static ADDRESS *mk_immediatelabel P1(EXPR *, ep) { return mk_expr(am_immed, ep); }

/*
 * make an indirect reference to a node
 */
static ADDRESS *mk_indirect P2(REG, reg, EXPR *, ep) {
  ADDRESS *ap;

  ap = mk_expr(am_indx, ep);
  ap->preg = reg;
  return ap;
}

#ifdef FLOAT_SUPPORT
/*
 * make a node to reference an immediate value f.
 */
static ADDRESS *mk_immedfloat P1(RVAL, f) {
  ADDRESS *ap;

  ap = mk_amode(am_immed);
  ap->u.offset = mk_fcon(&f, tp_double);
  return ap;
}
#endif /* FLOAT_SUPPORT */

static void allocate_blockrepeat_registers(void) { interrupt_restore_mask |= (1L << REG_RC) | (1L << REG_RS) | (1L << REG_RE); }

/*
 * Generate a label which points to an integer constant.  This routine
 * ensures that only one copy of the constant is generated.
 */
static ADDRESS *mk_ilabel P1(const EXPR *, ep) {
  ITREE *p, *q;
  int local_global = global_flag;
  LABEL lab;
  EXPRTYPE type;

  static ITREE *iitree = NULL;    /* Tree for integer constants */
  static ITREE *ilabtree = NULL;  /* Tree for label   constants */
  static ITREE *inatree = NULL;   /* Tree for na      constants */
  static ITREE *iexprtree = NULL; /* Tree for expr    constants */

  lab = nextlabel++;

  type = ep->nodetype;
  if (tst_iconst(ep)) {
    type = en_icon;
    /*
     *FATAL((__FILE__,"mk_ilabel", "icon not supportet now"));
     */
  }
  switch (type) {
  case en_icon:
    p = iitree;
    break;
  case en_nacon:
    p = inatree;
    break;
  case en_labcon:
    p = ilabtree;
    break;
  case en_add:
  case en_sub:
  case en_cast:
  case en_uminus:
    p = iexprtree;
    break;
  default:
    FATAL((__FILE__, "mk_ilabel", "illegal nodetype %d", type));
  }
  /* in the moment we do not try to build a tree */
  for (q = p; p; p = p->more) {
    if (is_equalnode(p->value, ep)) {
      return mk_label(p->label);
    }
    q = p;
  }
  global_flag = 1;
  p = (ITREE *)xalloc((int)sizeof(ITREE));
  p->label = lab;
  p->value = copy_iexpr(ep);
  p->less = p->more = NULL;
  global_flag = local_global;
  if (q == NULL) {
    switch (type) {
    case en_icon:
      iitree = p;
      break;
    case en_nacon:
      inatree = p;
      break;
    case en_labcon:
      ilabtree = p;
      break;
    case en_add:
    case en_sub:
    case en_cast:
    case en_uminus:
      iexprtree = p;
      break;
    default:
      break;
    }
  }
  /*else if (q->value < val) */
  /*  q->less = p;          */
  else
    q->more = p;
  put_kseg(alignment_of_type(tp_double));
  put_label(lab);
  put_pointer(ep);
  return mk_label(lab);
}

/*****************************************************************************/

static EXPR *copy_iexpr P1(const EXPR *, ep) {
  EXPR *newep;

  if (ep == NIL_EXPR)
    return NIL_EXPR;
  newep = copynode(ep);

  switch (ep->nodetype) {
  case en_icon:
  case en_autocon:
  case en_labcon:
  case en_nacon:
    return newep;
  case en_add:
  case en_sub:
    newep->v.p[0] = copy_iexpr(ep->v.p[0]);
    newep->v.p[1] = copy_iexpr(ep->v.p[1]);
    return newep;
  case en_cast:
  case en_uminus:
    newep->v.p[0] = copy_iexpr(ep->v.p[0]);
    return newep;
  default:
    FATAL((__FILE__, "copy_iexpr", "illegal nodetype %d", ep->nodetype));
    return NIL_EXPR;
  }
}

/**************************************************************************************/

/*
 * return true if the node passed can be used as offset in addressgeneration.
 */
static BOOL is_offset P1(const EXPR *, ep) { return is_icon(ep) && (ep->v.i >= -255L && ep->v.i <= 255L); }

/*
 * return true if the node passed can be generated as a short offset.
 */
static BOOL is_short P1(const EXPR *, ep) { return is_icon(ep) && (ep->v.i >= -32768L && ep->v.i <= 32767L); }

/*
 * return true if the node passed can be generated as a unsigned short
 * offset.
 */
static BOOL is_ushort P1(const EXPR *, ep) { return is_icon(ep) && (ep->v.i >= 0L && ep->v.i <= 0xFFFFL); }

/*
 * delivers true, if node can ba evaluated to an addressingmode
 * suitable for an 3-operand instruction
 * (register, *an, *+an(1), *-an(1), *-an(irm), *+an(irm))
 *                                   ^^^^^^^^^^^^^^^^^^^^-not included yet
 *
 * Autoincrements are currently not accepted for 3-op-instructions
 * ->could give troubles when both operands are the same address-
 *   registers (*arn++(1), *arm++(1), r) arn == arm
 *
 *
 * Attention!! do not forget to change makro is_op3_violated()
 *             if you add the auto-/pre-incre-/decre-ments
 */
static BOOL is_op3_possible(EXPR *node) {
  /* Look for register */
  if (node->nodetype == en_register) {
    return TRUE;
  }
  /* look for autocons *ar7+(1) or *ar7-(1) */
  if ((node->nodetype == en_autocon) && (node->v.i >= -1) && (node->v.i <= 1)) {
    return TRUE;
  }
  if (node->nodetype == en_ref) {
    switch (node->v.p[0]->nodetype) {
      /* Look for *arn */
    case en_register:
      if (is_address_register(node->v.p[0]->v.r)) {
        return TRUE;
      }
      break;
      /* look for indexnode *arn+(1) or *arn-(1) */
    case en_add:
      if ((node->v.p[0]->v.p[0]->nodetype == en_register) && (is_address_register(node->v.p[0]->v.p[0]->v.r)) &&
          is_icon(node->v.p[0]->v.p[1]) && (node->v.p[0]->v.p[1]->v.i >= -1) && (node->v.p[0]->v.p[1]->v.i <= 1)) {
        return TRUE;
      }
      /* look for indexnode *arn+(1) or *arn-(1), nodes of add swapped */
      if ((node->v.p[0]->v.p[1]->nodetype == en_register) && (is_address_register(node->v.p[0]->v.p[1]->v.r)) &&
          is_icon(node->v.p[0]->v.p[0]) && (node->v.p[0]->v.p[0]->v.i >= -1) && (node->v.p[0]->v.p[0]->v.i <= 1)) {
        return TRUE;
      }
      break;
#if 0 /* currently not supported */
	case en_ainc:
	case en_adec:
	    /* look for autoincre/decrement *arn++(1) / *arn--(1) */
	    if (ep->v.p[1]->v.i == 1
		&& ep->v.p[0]->nodetype == en_register
		&& is_address_register (ep->v.p[0]->v.r)) {
		return TRUE;
	    }
	    break;
	case en_asadd:
	case en_assub:
	    /* look for preincre/decrement *++arn(1) / *--arn(1) */
	    if (is_icon (ep->v.p[1])
		&& ep->v.p[1]->v.i == 1
		&& ep->v.p[0]->nodetype == en_register
		&& is_address_register (ep->v.p[0]->v.r)) {
		/* *++An(1) */
		return TRUE;
	    }
	    break;
#endif
    default:
      break;
    }
  }
  return FALSE;
}

#ifdef FLOAT_SUPPORT
BOOL is_short_float(const RVAL f, BTYPE tp) {
  int i;
  RVAL intpart;

  if ((f > MAX_POS_SHORT_FLOAT) || (f < MIN_NEG_SHORT_FLOAT))
    return (FALSE);
  if (f == 0.0)
    return (TRUE);
  if ((f > MAX_NEG_SHORT_FLOAT) && (f < MIN_POS_SHORT_FLOAT))
    return (FALSE);
  /*
   *  perhaps here should follow a check for the precision
   *  sinc shortfloats only offers a precision of 11 Mantissabits
   *  and sometimes we dont want to loose precision of constants
   *  but in the moment I dont know how to do this check
   *
   */
  /* We differ now in precission between float and (long-)double */

  /* we have 3 options (opt_shortfloat):
   * 0 we use shortfloats only if we are absolutely sure they
   *   wont bring any loss in precision
   *
   * 1 floats are allways represented in shortform if they are in
   *   range, double and longdouble only if there is no loss in
   *   precision
   *
   * 3 floats, doubles ans longdoubles  are allways represented
   *   in shortform if they are in range, there may be a loss in
   *   precision
   */

  if ((tp == bt_float) && (opt_shortfloat > 0))
    return (TRUE);

  if (opt_shortfloat > 1)
    return (TRUE);
  /* cut away the fractional part */
  i = (int)f;
  intpart = i;
  /* we use immediates for long and double only for
   * floats with no fractional part, then we can
   * be sure we dont loss any precission
   * It's not the best solution, but for now it has to do
   * it would be better to lock if the number has not more than
   * 12 significant mantissabit and if the exponent is between
   * +7 and -7 (base 2, of course), then the number can be represented
   * in the short form without any losses
   */
  if (intpart == f)
    return (TRUE);
#if 0
    /* New way to find out if a number can be represented with 11
     * mantissabits, needs still to be tested
     */
    /* shift mantissa, until first mantissabit has reached position
     * of bit 11 in an integer
     */
    if (f > 0.0) {
	while (f < ((double) (1L << 11))) {
	    f = f + f;
	}
    } else {
	while (f > ((double) (-(1L << 11)))) {
	    f = f + f;
	}
    }
    /* cut away the fractional part */
    i = (int) f;
    intpart = i;
    /* if there are no bits used in the fractionalpart we
     * may use the short integerformat
     */
    if (intpart == f)
	return (TRUE);

#endif
  return (FALSE);
}
#endif /* FLOAT_SUPPORT */

/*
 * tests if it is a labelfree constant node, that means either en_icon,
 * or sums or differences of such nodes
 */
static BOOL tst_iconst P1(const EXPR *, ep) {
  switch (ep->nodetype) {
  case en_icon:
    return TRUE;
  case en_add:
  case en_sub:
    return tst_iconst(ep->v.p[0]) && tst_iconst(ep->v.p[1]);
#ifndef RELOC_BUG
  case en_cast:
#endif
  case en_uminus:
    return tst_iconst(ep->v.p[0]);
  default:
    break;
  }
  return FALSE;
}

/*
 * Checks, if the given nacon-name is a valid
 * trapname, eg is __trap_00 to __trap_31.
 * also valid names are __trap_nn_xxxx, where
 * xxx is any valid sequence of identifiercharacters.
 * if so, returns an address containing the immediatevalue
 * of the trapnumber, otherwise returns NIL_ADDRESS
 * is used to convert functionscalls named __trap_nn to
 * trapu-opcodes, simplifies interface to operating-
 * systems.
 */

static ADDRESS *check_trap P1(const EXPR *, ep) {
  static const CHAR *trapname = (const CHAR *)"__trap_nn";
  const CHAR *p, *q;
  int i;

  /*
   *  Check if trapp option was enabled
   */
  if (opt_traps == OPT_NO) {
    return NIL_ADDRESS;
  }
  if (ep->nodetype == en_nacon) {
    p = ep->v.str;
    q = trapname;
    while (*q != 'n') {
      if (*q++ != *p++) {
        return NIL_ADDRESS;
      }
    }
    if ((*p > '3') || (*p < '0')) {
      return NIL_ADDRESS;
    }
    i = 10 * (*p++ - '0');
    if ((*p > '9') || (*p < '0')) {
      return NIL_ADDRESS;
    }
    i += (*p++ - '0');
    /* Check if number is in range and for end of string */
    if ((i > 31) || ((*p != 0) && (*p != '_'))) {
      return NIL_ADDRESS;
    }
    return (mk_immed(i));
  }
  return NIL_ADDRESS;
}

/*
 * mk_legal will coerce the addressing mode in ap1 into a mode that is
 * satisfactory for the flag word.
 */
static ADDRESS *mk_legal P3(ADDRESS *, ap, FLAGS, flags, ITYPE, size) {
  ADDRESS *ap2, *ap3;
  OPCODE OpSto, OpLd;

  if (flags & F_NOVALUE) {
    freeop(ap);
    return NIL_ADDRESS;
  }
  if (ap == NIL_ADDRESS) {
    FATAL((__FILE__, "mk_legal", "ap = 0"));
    return NIL_ADDRESS;
  }
  switch (size) {
  case OP_INT:
    OpSto = op_sti;
    OpLd = op_ldi;
    if (flags & F_FREG) {
      FATAL((__FILE__, "mk_legal", "op_int float mixed with integer"));
    }
    break;
  case OP_FLOAT:
    OpSto = op_stf;
    OpLd = op_ldf;
    if (flags & F_XREG) {
      FATAL((__FILE__, "mk_legal", "op_float float mixed with integer"));
    }
    break;
  default:
    FATAL((__FILE__, "mk_legal", "illegal size0"));
    break;
  }

  switch (ap->mode) {
  case am_immed:
    if (flags & F_IMMED) {
      return ap; /* mode ok */
    }
    break;
  case am_areg:
    if (flags & F_AREG && (!(flags & F_VOL) || is_temporary_register(ap->preg))) {
      return ap;
    }
    if (flags & F_FREG) {
      FATAL((__FILE__, "mk_legal", "am_areg float mixed with integer"));
    }
    break;
  case am_ireg:
    if (flags & F_IREG && (!(flags & F_VOL) || is_temporary_register(ap->preg))) {
      return ap;
    }
    if (flags & F_FREG) {
      FATAL((__FILE__, "mk_legal", "am_ireg float mixed with integer"));
    }
    break;
  case am_dreg:
    if (flags & F_DREG && (!(flags & F_VOL) || is_temporary_register(ap->preg))) {
      return ap;
    }
    if (flags & F_FREG) {
      FATAL((__FILE__, "mk_legal", "am_dreg float mixed with integer"));
    }
    break;
  case am_freg:
    if (flags & F_FREG && (!(flags & F_VOL) || is_temporary_register(ap->preg))) {
      return ap;
    }
    if (flags & F_XREG) {
      FATAL((__FILE__, "mk_legal", "am_freg float mixed with integer"));
    }
    break;
  case am_ind:
  case am_const_ind:
  case am_indx:
  case am_indx2:
  case am_indxs:
  case am_direct:
  case am_const_direct:
  case am_adec:
  case am_ainc:
  case am_preinc:
  case am_predec:
    if (flags & F_MEM)
      return ap;
    break;
  default:
    break;
  }
  if ((flags & F_XREG) != 0) {
    /* decide, which mode is better */
    if (is_free_data() && (flags & F_DREG)) {
      freeop(ap);                  /* maybe we can use it... */
      ap2 = data_register(F_DREG); /* allocate to dreg */
      g_code(op_ldi, OP_INT, ap, ap2);
      return ap2;
    }
    if (is_free_addr() && (flags & F_AREG)) {
      freeop(ap);               /* maybe we can use it... */
      ap2 = address_register(); /* allocate to dreg */
      g_code(op_ldi, OP_INT, ap, ap2);
      return ap2;
    }
    if (is_free_ireg() && (flags & F_IREG)) {
      freeop(ap);
      ap2 = index_register();
      g_code(op_ldi, OP_INT, ap, ap2);
      return ap2;
    }
  }
  if (flags & F_DREG) {
    freeop(ap);                  /* maybe we can use it... */
    ap2 = data_register(F_DREG); /* allocate to dreg */
    g_code(op_ldi, OP_INT, ap, ap2);
    return ap2;
  }
  if (flags & F_FREG) {
    freeop(ap);                  /* maybe we can use it... */
    ap2 = data_register(F_FREG); /* allocate to dreg */
    g_code(op_ldf, OP_FLOAT, ap, ap2);
    return ap2;
  }
  if (flags & F_AREG) {
    freeop(ap);
    ap2 = address_register();
    g_code(op_ldi, OP_INT, ap, ap2);
    return ap2;
  }
  if (flags & F_IREG) {
    freeop(ap);
    ap2 = index_register();
    g_code(op_ldi, OP_INT, ap, ap2);
    return ap2;
  }
  if (flags & F_MEM) {
    if (ap->mode == am_immed) {
      /* we can not store immediates directly in memory */
      freeop(ap);
      ap3 = data_register((size == OP_INT) ? F_DREG : F_FREG);
      g_code(OpLd, size, ap, ap3);
      ap = ap3;
    }
    freeop(ap);
    ap2 = mk_scratch(1L);
    /* copy value into memory */
    g_code(OpSto, size, ap, ap2);
    return ap2;
  }
  FATAL((__FILE__, "mk_legal", ""));
  return NIL_ADDRESS;
}

/*****************************************************************************/

/*
 * add a compiler generated label to the peep list.
 */
PRIVATE void g_label P1(LABEL, labno) {
  sync_stack();
  g_code(op_label, OP_INT, mk_label(labno), NIL_ADDRESS);
}

#ifdef DEBUGOPT
/*
 * add a source line number to the peep list.
 */
PRIVATE void g_line P2(LINE, line, const CHAR *, linetxt) {
  g_code3(op_line, OP_INT, mk_line(line), mk_linetxt(linetxt), NIL_ADDRESS);
}

#endif /*DEBUGOPT */
/*
 * add a conditional branch instruction to the peep list.
 */
static void g_cbranch P2(OPCODE, op, LABEL, labno) {
  sync_stack();
  g_code(op, OP_INT, mk_Jumplabel(labno), NIL_ADDRESS);
}

/*
 * add a branch instruction to the peep list.
 */
PRIVATE void g_branch P1(LABEL, labno) { g_cbranch(op_br, labno); }

/*
 * adjust the stack by "bytes" bytes.
 */
PRIVATE void g_stack P1(SIZE, bytes) {
  if (bytes != 0L) {
    /* adjust stack pointer */
    g_immed(op_subi, bytes, mk_reg(STACKPTR));
    stack_offset -= bytes;
    if (max_stack_adjust < bytes)
      max_stack_adjust = bytes;
  }
}

/*
 * Generate an instruction which takes an immediate option with optimal
 * (for space) instruction(s).
 */
static void g_immed P3(OPCODE, op, IVAL, i, ADDRESS *, ap) {
  if (ap != NIL_ADDRESS) {
    if (!isanyreg(ap))
      FATAL((__FILE__, "g_immed", "immed-to-memory"));
  }
  if ((i >= -32768L && i <= 32767L) || (opt_const_in_ram != OPT_NO)) {
    g_code(op, OP_INT, mk_immed(i), ap);
  } else {
    /* bigger constants we must build by hand */
    /* in future it could be solved through storing constants */
    /* in datasegment and fetching them from there */
    ADDRESS *ap1;
    IVAL low = i & 0xFFFFL;
    IVAL high = i >> 16;

    if (op == op_ldi) {
      ap1 = ap;
    } else {
      ap1 = temporary_register(F_XREG);
    }
    g_code(op_ldi, OP_INT, mk_immed(high), ap1);
    if (high != 0) {
      g_code(op_lsh, OP_INT, mk_immed(16), ap1);
    }
    if (low != 0) {
      g_code(op_or, OP_INT, mk_uimmed(low), ap1);
    }
    if (op != op_ldi) {
      g_code(op, OP_INT, ap1, ap);
      freeop(ap1);
    }
  }
}

/*
 * Generate an instruction which takes an unsigned immediate option with
 * optimal (for space) instruction(s).
 */
static void g_uimmed P3(OPCODE, op, IVAL, i, ADDRESS *, ap) {
  if (ap != NIL_ADDRESS) {
    if (!isanyreg(ap))
      FATAL((__FILE__, "g_uimmed", "immed-to-memory"));
  }
  if ((i >= 0 && i <= 0xFFFFL) || (opt_const_in_ram != OPT_NO)) {
    g_code(op, OP_INT, mk_uimmed(i), ap);
  } else {
    /* bigger constants we must build by hand */
    /* in future it could be solved through storing constants */
    /* in datasegment and fetching them from there */
    ADDRESS *ap1 = temporary_register(F_XREG);
    IVAL low = i & 0xFFFFL;
    IVAL high = i >> 16;

    g_code(op_ldi, OP_INT, mk_immed(high), ap1);
    if (high != 0) {
      g_code(op_lsh, OP_INT, mk_immed(16), ap1);
    }
    if (low != 0) {
      g_code(op_or, OP_INT, mk_uimmed(low), ap1);
    }
    g_code(op, OP_INT, ap1, ap);
    freeop(ap1);
  }
}

/*----------------------------------------------------------------------------*/

/*
 * generate code to evaluate an index node and return the addressing
 * mode of the result.
 */
static ADDRESS *g_index P1(const EXPR *, ep) {
  ADDRESS *ap1, *ap2;
  EXPR *ep0 = ep->v.p[0];
  EXPR *ep1 = ep->v.p[1];
  AMODE mode;

  /*
   *  Try and ensure that we evaluate address registers first ....
   *  this leads to better code.
   */
  switch (ep->nodetype) {
  case en_add:
    if (ep1->nodetype == en_register && is_address_register(ep1->v.r)) {
      ep0 = ep->v.p[1];
      ep1 = ep->v.p[0];
    }
    mode = am_indx2;
    break;
  case en_sub:
    mode = am_indxs;
    break;
  default:
    FATAL((__FILE__, "g_index", "illegal nodetype %d ", ep->nodetype));
  }
  if (ep1->nodetype == en_register && ep0->nodetype == en_register) {
    if (is_address_register(ep0->v.r) || (ep->nodetype == en_sub)) {
      /* first node is address register */
      ap1 = g_expr(ep0, F_AREG);
      ap1 = copy_addr(ap1, mode);
      ap2 = g_expr(ep1, F_IREG);
      ap1->sreg = ap2->preg;
      ap1->deep = ap2->deep;
      ap1->u.offset = mk_const(0L);
      return ap1;
    } else if (is_address_register(ep1->v.r) && (ep->nodetype == en_add)) {
      /* second node is address register */
      ap1 = g_expr(ep1, F_AREG);
      ap1 = copy_addr(ap1, am_indx2); /* (ARx,IRx) */
      ap2 = g_expr(ep0, F_IREG);
      ap1->sreg = ap2->preg;
      ap1->deep = ap2->deep;
      ap1->u.offset = mk_const(0L);
      return ap1;
    }
  }
  /*
   *   The general case (no register)
   */
  ap1 = g_expr(ep0, (ep->nodetype == en_add) ? (FLAGS)(F_AREG | F_IMMED) : F_AREG);
  switch (ap1->mode) {
  case am_areg:
    ap2 = g_expr(ep1, (FLAGS)(F_IREG | F_IMMED));
    validate(ap1);
    break;
  case am_immed:
    if (ep->nodetype == en_sub) {
      FATAL((__FILE__, "g_index", "illegal adressmodee"));
    }
    ap2 = ap1;
    ap1 = g_expr(ep1, (FLAGS)(F_AREG | F_IMMED));
    validate(ap2);
    break;
  default:
    CANNOT_REACH_HERE();
  }
  /*
   *  possible combinations:
   *
   *          F_IMMED +/- F_IMMED
   *          F_AREG  +/- F_IMMED
   *          F_AREG  +/- F_IREG
   */

  if (ap1->mode == am_areg) {
    /*
     *  watch out for:
     *          register(addr) + index_register
     *          register(addr) + data_register
     */
    if (!is_temporary_register(ap1->preg)) {
      /* ap1 = tempref address register */
      ap1 = copy_addr(ap1, ap1->mode);
      switch (ap2->mode) {
      case am_ireg:
        /* 0(ARx,IRy) */
        ap1->mode = mode;
        ap1->sreg = ap2->preg;
        ap1->deep = ap2->deep;
        ap1->u.offset = mk_const(0L);
        return ap1;
      case am_immed:
        if (!is_offset(ap2->u.offset))
          /* we want to add to ap1 later... */
          /* so copy it in scratchregister */
          ap1 = mk_legal(ap1, (FLAGS)(F_AREG | F_VOL), OP_INT);
        break;
      default:
        break;
      }

/* needs some changes in the registermanagement before this can be done */
/* we cannot correctly restore second temp if it has been pushed        */
/* (we have only one depth-information per ap and so can only keep      */
/* of one tempregister                                                  */
#if 0
	    error, not suported now
	} else {
	    /* ap1 is temporaryregister */
	    switch (ap2->mode) {
	    case am_ireg:
		/* 0(ARx,IRy) */
		ap1 = copy_addr (ap1, ap1->mode);
		ap1->mode = am_indx2;
		ap1->sreg = ap2->preg;
		ap1->u.offset = mk_const (0L);
		return ap1;
	    default:
		break;
	    }
#endif
    }
  }
  if (ap2->mode == am_immed) {
    if (ap1->mode == am_immed) {
      ap1 = copy_addr(ap1, am_direct);
      if (ep->nodetype == en_add) {
        ap1->u.offset = mk_add(ap1->u.offset, ap2->u.offset);
      } else {
        ap1->u.offset = mk_node(en_sub, ap1->u.offset, ap2->u.offset, tp_void);
      }
      return ap1;
    }
    if (is_offset(ap2->u.offset)) {
      ap1 = mk_legal(ap1, F_AREG, OP_INT);
      ap1 = copy_addr(ap1, am_indx);
      if (ep->nodetype == en_add) {
        ap1->u.offset = ap2->u.offset;
      } else {
        ap1->u.offset = mk_const(-ap2->u.offset->v.i);
      }
      return ap1;
    }
  }
  /* just to be sure, ap1 should allready be volatile here... */
  if (!is_temporary_register(ap1->preg)) {
    /* ap1 is not volatile ... */
    ap1 = mk_legal(ap1, (FLAGS)(F_AREG | F_VOL), OP_INT);
  }
  if (ep->nodetype == en_add) {
    g_code(op_addi, OP_INT, ap2, ap1); /* add left to address reg */
  } else {
    g_code(op_subi, OP_INT, ap2, ap1); /* sub left to address reg */
  }
  ap1 = copy_addr(ap1, am_ind);
  freeop(ap2); /* release any temps in ap2 */
  return ap1;  /* return indirect */
}

/*
 * return the addressing mode of a dereferenced node.
 */
static ADDRESS *g_deref P3(const EXPR *, ep, TYP *, tp, FLAGS, flags) {
  ADDRESS *ap1;

  /*
   * If a reference to a struct/union is required, return a pointer to the
   * struct instead
   */
  if (is_structure_type(tp) || is_array_assignment(tp)) {
    return g_expr(ep, F_IALL);
  }
  switch (ep->nodetype) {
#ifdef DEBUG
  case en_sub:
#endif
  case en_add:
    return g_index(ep);
  case en_autocon:
    if (ep->v.i >= -255L && ep->v.i < 255L) {
      ap1 = mk_indirect(frameptr, mk_const(ep->v.i));
    } else {
      ap1 = address_register();
      g_immed(op_ldi, ep->v.i, ap1);
      g_code(op_addi, OP_INT, mk_reg(frameptr), ap1);
      ap1 = copy_addr(ap1, am_ind);
    }
    return ap1;
  case en_ainc:
    /* special TMS320C30 instructions */
    if (ep->v.p[1]->v.i <= 255L  /* if size less than max autoincrement */
        && ep->v.p[1]->v.i >= 0L /* and if size positive */
        && ep->v.p[0]->nodetype == en_register && is_address_register(ep->v.p[0]->v.r) && !(flags & F_USES)) {
      /* (An)+ */
      ap1 = mk_amode(am_ainc);
      ap1->preg = ep->v.p[0]->v.r;
      ap1->u.offset = mk_const(ep->v.p[1]->v.i);
      return ap1;
    }
    break;
  case en_adec:
    /* special TMS320C30 instructions */
    if (ep->v.p[1]->v.i <= 255L  /* if size less than max autoincrement */
        && ep->v.p[1]->v.i >= 0L /* and if size positive */
        && ep->v.p[0]->nodetype == en_register && is_address_register(ep->v.p[0]->v.r) && !(flags & F_USES)) {
      /* (An)- */
      ap1 = mk_amode(am_adec);
      ap1->preg = ep->v.p[0]->v.r;
      ap1->u.offset = mk_const(ep->v.p[1]->v.i);
      return ap1;
    }
    break;
  case en_asadd:
    /* special TMS320C30 instructions */
    if (is_icon(ep->v.p[1]) && ep->v.p[1]->v.i <= 255L /* if size less than max autoincrement */
        && ep->v.p[1]->v.i >= 0L                       /* and if size positive */
        && ep->v.p[0]->nodetype == en_register && is_address_register(ep->v.p[0]->v.r) && !(flags & F_USES)) {
      /* ++(An) */
      ap1 = mk_amode(am_preinc);
      ap1->preg = ep->v.p[0]->v.r;
      ap1->u.offset = mk_const(ep->v.p[1]->v.i);
      return ap1;
    }
    break;
  case en_assub:
    /* special TMS320C30 instructions */
    if (is_icon(ep->v.p[1]) && ep->v.p[1]->v.i <= 255L /* if size less than max autoincrement */
        && ep->v.p[1]->v.i >= 0L                       /* and if size positive */
        && ep->v.p[0]->nodetype == en_register && is_address_register(ep->v.p[0]->v.r) && !(flags & F_USES)) {
      /* --(An) */
      ap1 = mk_amode(am_predec);
      ap1->preg = ep->v.p[0]->v.r;
      ap1->u.offset = mk_const(ep->v.p[1]->v.i);
      return ap1;
    }
    break;
  default:
    break;
  }
  /*
   * F_DIRECT Supresses to make a doubleindirection for
   * immediates, sinc it will be converted in an direct-reference
   */
  ap1 = g_expr(ep, (FLAGS)(F_AREG | F_IMMED | F_DIRECT)); /* generate address */
  if (ap1->mode == am_areg) {
    return copy_addr(ap1, am_ind);
  }
  return copy_addr(ap1, am_direct);
}

/*
 * get a bitfield value
 */
static ADDRESS *g_fderef P2(const EXPR *, ep, FLAGS, flags) {
  ADDRESS *ap;

  ap = g_deref(ep->v.p[0], ep->etp, (FLAGS)(F_IALL));
  ap = mk_legal(ap, (FLAGS)(F_XREG | F_VOL), OP_INT);
  g_rotate(ap, (int)ep->v.bit.offset, ep->etp, ep->v.bit.width);
  return mk_legal(ap, flags, OP_INT);
}

/*============================================================================*/

/*
 * generate code to evaluate a unary minus or complement. float: unary minus
 * calls a library function
 */
static ADDRESS *g_unary P3(const EXPR *, ep, FLAGS, flags, OPCODE, op) {
  ADDRESS *ap, *ap2;

  switch (ep->etp->type) {
  case bt_uchar:
  case bt_schar:
  case bt_char:
  case bt_charu:
  case bt_short:
  case bt_ushort:
  case bt_int16:
  case bt_uint16:
  case bt_int32:
  case bt_uint32:
  case bt_long:
  case bt_ulong:
  case bt_pointer32:
    ap = g_expr(ep->v.p[0], (FLAGS)(op == op_not ? F_IALL | F_UNSIGNED : F_IALL));

    /* maybe we can use ap... */
    freeop(ap);

    ap2 = temporary_register(best_flags(flags, F_XREG));
    g_code(op, OP_INT, ap, ap2);
    return mk_legal(ap2, flags, OP_INT);
  case bt_float:
  case bt_double:
  case bt_longdouble:
    if (op == op_negi) {
      ap = g_expr(ep->v.p[0], (FLAGS)(F_FALL));

      /* maybe we can use ap... */
      freeop(ap);

      ap2 = temporary_register(F_FREG);
      g_code(op_negf, OP_FLOAT, ap, ap2);
      return mk_legal(ap2, flags, OP_FLOAT);
    }
    /* Fall through */
  default:
    FATAL((__FILE__, "g_unary", "illegal type %d or operation %d", ep->etp->type, op));
    break;
  }
  return NIL_ADDRESS;
}

/*============================================================================*/

/*
 * generate an auto increment or decrement node. op should be either op_add
 * (for increment) or op_sub (for decrement).
 */
static ADDRESS *g_aincdec P3(const EXPR *, ep, FLAGS, flags, OPCODE, op) {
  ADDRESS *ap1, *ap2, *ap3;

  switch (ep->etp->type) {
  case bt_uchar:
  case bt_schar:
  case bt_char:
  case bt_charu:
  case bt_short:
  case bt_ushort:
  case bt_int16:
  case bt_uint16:
  case bt_int32:
  case bt_uint32:
  case bt_long:
  case bt_ulong:
  case bt_pointer32:
    if (ep->v.p[0]->nodetype == en_fieldref)
      return g_asbitfield(ep, flags, op, TRUE);
    if (flags & F_NOVALUE) { /* dont need result */
      ap1 = g_expr(ep->v.p[0], (FLAGS)(F_IALL));
      /* if ap1 is in register we can modify it directly */
      if (isanyreg(ap1)) {
        g_immed(op, ep->v.p[1]->v.i, ap1);
      } else {
        /* else we must get ap1 in a register, modify it and store it again */
        ap2 = temporary_register(F_XREG);
        g_code(op_ldi, OP_INT, ap1, ap2);
        g_immed(op, ep->v.p[1]->v.i, ap2);
        g_code(op_sti, OP_INT, ap2, ap1);
        freeop(ap2);
      }
      return mk_legal(ap1, flags, OP_INT);
    }
    ap1 = temporary_register(best_flags(flags, F_XREG));
    ap2 = g_expr(ep->v.p[0], (FLAGS)(F_IALL | F_USES));
    validate(ap1);
    g_code(op_ldi, OP_INT, ap2, ap1);
    /* if ap2 is in register we can modify it directly */
    if (isanyreg(ap2)) {
      g_immed(op, ep->v.p[1]->v.i, ap2);
    } else {
      /* else we must get ap2 in a register, modify it and store it again */
      ap3 = temporary_register(F_XREG);
      g_code(op_ldi, OP_INT, ap1, ap3);
      g_immed(op, ep->v.p[1]->v.i, ap3);
      g_code(op_sti, OP_INT, ap3, ap2);
      freeop(ap3);
    }
    freeop(ap2);
    return mk_legal(ap1, flags, OP_INT);
#ifdef FLOAT_SUPPORT
  case bt_float:
  case bt_double:
  case bt_longdouble:
    if (flags & F_NOVALUE) { /* dont need result */
      ap1 = g_expr(ep->v.p[0], F_FALL);
      /* if ap1 is in register we can modify it directly */
      if (ap1->mode == am_freg) {
        g_code(op, OP_FLOAT, mk_immedfloat((double)ep->v.p[1]->v.f), ap1);
      } else {
        /* else we must get ap1 in a register, modify it and store it again */
        ap2 = temporary_register(F_FREG);
        g_code(op_ldf, OP_FLOAT, ap1, ap2);
        g_code(op, OP_FLOAT, mk_immedfloat((double)ep->v.p[1]->v.f), ap2);
        g_code(op_stf, OP_FLOAT, ap2, ap1);
        freeop(ap2);
      }
      return mk_legal(ap1, flags, OP_FLOAT);
    }
    ap1 = temporary_register(F_FREG);
    ap2 = g_expr(ep->v.p[0], (FLAGS)(F_FALL | F_USES));
    validate(ap1);
    g_code(op_ldf, OP_FLOAT, ap2, ap1);
    /* if ap2 is in register we can modify it directly */
    if (ap2->mode == am_freg) {
      g_code(op, OP_FLOAT, mk_immedfloat((double)ep->v.p[1]->v.f), ap2);
    } else {
      /* else we must get ap2 in a register, modify it and store it again */
      ap3 = temporary_register(F_FREG);
      g_code(op_ldf, OP_FLOAT, ap1, ap3);
      g_code(op, OP_FLOAT, mk_immedfloat((double)ep->v.p[1]->v.f), ap3);
      g_code(op_stf, OP_FLOAT, ap3, ap2);
      freeop(ap3);
    }
    freeop(ap2);
    return mk_legal(ap1, flags, OP_FLOAT);
#endif /* FLOAT_SUPPORT */
  default:
    FATAL((__FILE__, "g_aincdec", "illegal type %d or float", ep->etp->type));
    break;
  }
  return NIL_ADDRESS;
}

/*============================================================================*/

/*
 * generate code to evaluate a binary node and return the addressing mode of
 * the result.
 */
static ADDRESS *g_addsub P3(const EXPR *, ep, FLAGS, flags, OPCODE, op) {
  ADDRESS *ap1, *ap2, *ap3;

  switch (ep->etp->type) {
  case bt_uchar:
  case bt_schar:
  case bt_char:
  case bt_charu:
  case bt_short:
  case bt_ushort:
  case bt_int16:
  case bt_uint16:
  case bt_int32:
  case bt_uint32:
  case bt_long:
  case bt_ulong:
  case bt_pointer32:
    if (is_op3_possible(ep->v.p[0]) && is_op3_possible(ep->v.p[1])) {
      ap1 = g_expr(ep->v.p[0], (FLAGS)(F_XREG | F_MEM));
      ap2 = g_expr(ep->v.p[1], (FLAGS)(F_XREG | F_MEM));
      /* Just to be sure... check again for correct op3-operands */
      if (is_op3_violated(ap1) || is_op3_violated(ap2)) {
        FATAL((__FILE__, "g_addsub", "inconsistency int "));
      }
      validate(ap1);
      freeop(ap2);
      freeop(ap1);
      ap3 = temporary_register(best_flags(flags, F_XREG));
      g_code3((op == op_addi ? op_addi3 : op_subi3), OP_INT, ap2, ap1, ap3);
      ap1 = ap3;
    } else {
      if (tst_iconst(ep->v.p[0])) {
        ap1 = g_expr(ep->v.p[1], (FLAGS)(F_VOL | best_flags(flags, F_XREG)));
        ap2 = g_expr(ep->v.p[0], F_IALL);
        if (op == op_subi)
          op = op_subri;
      } else {
        ap1 = g_expr(ep->v.p[0], (FLAGS)(F_VOL | best_flags(flags, F_XREG)));
        ap2 = g_expr(ep->v.p[1], F_IALL);
      }
      validate(ap1); /* in case push occurred */
      g_code(op, OP_INT, ap2, ap1);
      freeop(ap2);
    }
    return mk_legal(ap1, flags, OP_INT);
  case bt_longdouble:
  case bt_double:
  case bt_float:
    op = (op == op_addi) ? op_addf : op_subf;
    if (is_op3_possible(ep->v.p[0]) && is_op3_possible(ep->v.p[1])) {
      ap1 = g_expr(ep->v.p[0], (FLAGS)(F_FREG | F_MEM));
      ap2 = g_expr(ep->v.p[1], (FLAGS)(F_FREG | F_MEM));
      /* Just to be sure... check again for correct op3-operands */
      if (is_op3_violated(ap1) || is_op3_violated(ap2)) {
        FATAL((__FILE__, "g_addsub", "inconsistency float "));
      }
      validate(ap1);
      freeop(ap2);
      freeop(ap1);
      ap3 = temporary_register(F_FREG);
      g_code3((op == op_addf ? op_addf3 : op_subf3), OP_FLOAT, ap2, ap1, ap3);
      ap1 = ap3;
    } else {
      if (ep->v.p[0]->nodetype == en_fcon) {
        ap1 = g_expr(ep->v.p[1], (FLAGS)(F_VOL | F_FREG));
        ap2 = g_expr(ep->v.p[0], F_FALL);
        if (op == op_subf)
          op = op_subrf;
      } else {
        ap1 = g_expr(ep->v.p[0], (FLAGS)(F_VOL | F_FREG));
        ap2 = g_expr(ep->v.p[1], F_FALL);
      }
      validate(ap1); /* in case push occurred */
      g_code(op, OP_FLOAT, ap2, ap1);
      freeop(ap2);
    }
    return mk_legal(ap1, flags, OP_FLOAT);
  default:
    FATAL((__FILE__, "g_addsub", "illegal type %d", ep->etp->type));
    break;
  }
  return NIL_ADDRESS;
}

/*
 * generate a plus equal or a minus equal node.
 */
static ADDRESS *g_asadd P3(const EXPR *, ep, FLAGS, flags, OPCODE, op) {
  FLAGS flagx;
  ADDRESS *ap1, *ap2, *ap3;

  switch (ep->etp->type) {
  case bt_char:
  case bt_charu:
  case bt_schar:
  case bt_uchar:
  case bt_short:
  case bt_ushort:
  case bt_int16:
  case bt_uint16:
  case bt_int32:
  case bt_uint32:
  case bt_long:
  case bt_ulong:
  case bt_pointer32:
    if (ep->v.p[0]->nodetype == en_fieldref)
      return g_asbitfield(ep, flags, op, FALSE);
    if (flags & F_NOVALUE)
      flagx = F_IALL;
    else
      flagx = (FLAGS)(F_IALL | F_USES);
    ap1 = g_expr(ep->v.p[0], flagx);

    if (isanyreg(ap1)) {
      ap2 = g_expr(ep->v.p[1], (FLAGS)(F_IALL));
      validate(ap1);
      g_code(op, OP_INT, ap2, ap1);
    } else {
      ap2 = g_expr(ep->v.p[1], (FLAGS)(F_IALL));
      validate(ap1);
      ap3 = temporary_register(F_XREG);
      g_code(op_ldi, OP_INT, ap1, ap3);
      g_code(op, OP_INT, ap2, ap3);
      g_code(op_sti, OP_INT, ap3, ap1);
      freeop(ap3);
    }
    freeop(ap2);
    return mk_legal(ap1, flags, OP_INT);
  case bt_float:
  case bt_double:
  case bt_longdouble:
    op = (op == op_addi) ? op_addf : op_subf;
    flagx = (flags & F_NOVALUE) ? F_FALL : (FLAGS)(F_FALL | F_USES);
    ap1 = g_expr(ep->v.p[0], flagx);
    if (ap1->mode == am_freg) {
      ap2 = g_expr(ep->v.p[1], (FLAGS)(F_FREG | F_MEM | F_IMMED));
      validate(ap1);
      g_code(op, OP_FLOAT, ap2, ap1);
    } else {
      ap2 = g_expr(ep->v.p[1], (FLAGS)(F_FREG | F_MEM | F_IMMED));
      validate(ap1);
      ap3 = temporary_register(F_FREG);
      g_code(op_ldf, OP_FLOAT, ap1, ap3);
      g_code(op, OP_FLOAT, ap2, ap3);
      g_code(op_stf, OP_FLOAT, ap3, ap1);
      freeop(ap3);
    }
    freeop(ap2);
    return mk_legal(ap1, flags, OP_FLOAT);
  default:
    FATAL((__FILE__, "asadd", "illegal type %d", ep->etp->type));
    break;
  }
  return NIL_ADDRESS;
}

/*============================================================================*/

/*
 * generate code to evaluate a restricted binary node and return the
 * addressing mode of the result.
 */
static ADDRESS *g_logic P3(const EXPR *, ep, FLAGS, flags, OPCODE, op) {
  ADDRESS *ap1, *ap2, *ap3;

  if (is_op3_possible(ep->v.p[0]) && is_op3_possible(ep->v.p[1])) {
    ap1 = g_expr(ep->v.p[0], (FLAGS)(F_XREG | F_MEM));
    ap2 = g_expr(ep->v.p[1], (FLAGS)(F_XREG | F_MEM));
    validate(ap1);
    /* Just to be sure... check again for correct op3-operands */
    if (is_op3_violated(ap1) || is_op3_violated(ap2)) {
      FATAL((__FILE__, "g_logic", "inconsistency int "));
    }
    switch (op) {
    case op_and:
      op = op_and3;
      break;
    case op_andn:
      op = op_andn3;
      break;
    case op_or:
      op = op_or3;
      break;
    case op_xor:
      op = op_xor3;
      break;
    default:
      FATAL((__FILE__, "g_logic", "illegal opcode %d", op));
      break;
    }
    freeop(ap2);
    freeop(ap1);
    ap3 = temporary_register(best_flags(flags, F_XREG));
    g_code3(op, OP_INT, ap2, ap1, ap3);
    ap1 = ap3;
  } else {
    if (tst_iconst(ep->v.p[0])) {
      ap1 = g_expr(ep->v.p[1], (FLAGS)(F_VOL | best_flags(flags, F_XREG)));
      ap2 = g_expr(ep->v.p[0], (FLAGS)(F_IALL | F_UNSIGNED));
    } else {
      ap1 = g_expr(ep->v.p[0], (FLAGS)(F_VOL | best_flags(flags, F_XREG)));
      ap2 = g_expr(ep->v.p[1], (FLAGS)(F_IALL | F_UNSIGNED));
    }
    validate(ap1); /* in case push occurred */
    g_code(op, OP_INT, ap2, ap1);
    freeop(ap2);
  }
  return mk_legal(ap1, flags, OP_INT);
}

/*
 * generate a &= or a |= node.
 */
static ADDRESS *g_aslogic P3(const EXPR *, ep, FLAGS, flags, OPCODE, op) {
  FLAGS flagx;
  ADDRESS *ap1, *ap2;

  if (ep->v.p[0]->nodetype == en_fieldref)
    return g_asbitfield(ep, flags, op, FALSE);
  flagx = (flags & F_NOVALUE) ? F_IALL : (FLAGS)(F_IALL | F_USES);
  ap1 = g_expr(ep->v.p[0], flagx);
  if (isanyreg(ap1)) {
    ap2 = g_expr(ep->v.p[1], (FLAGS)(F_IALL | F_UNSIGNED));
  } else {
    ap2 = g_expr(ep->v.p[1], F_XREG);
  }
  validate(ap1);
  if (isanyreg(ap1)) {
    g_code(op, OP_INT, ap2, ap1);
  } else {
    ap2 = mk_legal(ap2, (FLAGS)(F_VOL | F_XREG), OP_INT);
    g_code(op, OP_INT, ap1, ap2);
    g_code(op_sti, OP_INT, ap2, ap1);
  }
  freeop(ap2);
  return mk_legal(ap1, flags, OP_INT);
}

/*============================================================================*/

/*
 * generate code to evaluate a shift node and return the address mode of the
 * result.
 * Note: right shifts will have already been converted to negative left
 * shifts.
 */
static ADDRESS *g_shift P3(const EXPR *, ep, FLAGS, flags, OPCODE, op) {
  ADDRESS *ap1, *ap2, *ap3;

  if (is_op3_possible(ep->v.p[0]) && is_op3_possible(ep->v.p[1])) {
    ap1 = g_expr(ep->v.p[0], (FLAGS)(F_XREG | F_MEM));
    ap2 = g_expr(ep->v.p[1], (FLAGS)(F_XREG | F_MEM));
    validate(ap1);
    /* Just to be sure... check again for correct op3-operands */
    if (is_op3_violated(ap1) || is_op3_violated(ap2)) {
      FATAL((__FILE__, "g_shift", "inconsistency int "));
    }
    switch (op) {
    case op_lsh:
      op = op_lsh3;
      break;
    case op_ash:
      op = op_ash3;
      break;
    default:
      FATAL((__FILE__, "g_shift", "illegal opcode %d", op));
      break;
    }
    freeop(ap2);
    freeop(ap1);
    ap3 = temporary_register(best_flags(flags, F_XREG));
    g_code3(op, OP_INT, ap2, ap1, ap3);
    ap1 = ap3;
  } else {
    ap1 = g_expr(ep->v.p[0], (FLAGS)(F_VOL | best_flags(flags, F_XREG)));
    ap2 = g_expr(ep->v.p[1], F_IALL);

    validate(ap1);
    g_code(op, OP_INT, ap2, ap1);
    freeop(ap2);
  }
  return mk_legal(ap1, flags, OP_INT);
}

/*
 * generate shift equals operators.
 */
static ADDRESS *g_asshift P3(const EXPR *, ep, FLAGS, flags, OPCODE, op) {
  FLAGS flagx;
  ADDRESS *ap1, *ap2, *ap3;

  switch (ep->etp->type) {
  case bt_uchar:
  case bt_schar:
  case bt_char:
  case bt_charu:
  case bt_ushort:
  case bt_short:
  case bt_int16:
  case bt_uint16:
  case bt_int32:
  case bt_uint32:
  case bt_ulong:
  case bt_long:
  case bt_pointer32:
    if (ep->v.p[0]->nodetype == en_fieldref)
      return g_asbitfield(ep, flags, op, FALSE);
    flagx = (flags & F_NOVALUE) ? F_IALL : (FLAGS)(F_IALL | F_USES);
    ap1 = g_expr(ep->v.p[0], flagx);
    ap2 = g_expr(ep->v.p[1], (FLAGS)(F_IALL));
    validate(ap1);
    if (isanyreg(ap1)) {
      g_code(op, OP_INT, ap2, ap1);
    } else {
      ap3 = temporary_register(F_XREG);
      g_code(op_ldi, OP_INT, ap1, ap3);
      g_code(op, OP_INT, ap2, ap3);
      g_code(op_sti, OP_INT, ap3, ap1);
      freeop(ap3);
    }
    freeop(ap2);
    return mk_legal(ap1, flags, OP_INT);
  default:
    FATAL((__FILE__, "g_asshift", "illegal type %d", ep->etp->type));
    break;
  }
  return NIL_ADDRESS;
}

/*============================================================================*/

/*
 * generate code to evaluate a divide operator
 */
static ADDRESS *g_div P3(const EXPR *, ep, FLAGS, flags, BOOL, mod) {

  BOOL is_signed = FALSE;
  ADDRESS *ap1, *ap2;

  switch (ep->etp->type) {
  case bt_char:
  case bt_schar:
  case bt_short:
  case bt_int16:
  case bt_int32:
  case bt_long:
    is_signed = TRUE;
    /*FALLTHRU */
  case bt_uchar:
  case bt_charu:
  case bt_ushort:
  case bt_uint16:
  case bt_uint32:
  case bt_ulong:
  case bt_pointer32:
    temp_inv();
    ap1 = g_expr(ep->v.p[0], F_IALL);
    ap2 = g_expr(ep->v.p[1], F_IALL);
    validate(ap1);
    freeop(ap2);
    freeop(ap1);
    if (ap2->preg == REG_R0) {
      /* bad luck, parameter is using space for ap1 */
      if (ap1->preg == REG_R1) {
        /* its worse, a2 is in r0 and a1 is in r1 */
        g_code(op_ldi, OP_INT, ap2, mk_reg(REG_AR0));
        g_code(op_ldi, OP_INT, ap1, mk_reg(REG_R0));
        g_code(op_ldi, OP_INT, mk_reg(REG_AR0), mk_reg(REG_R1));
      } else {
        g_code(op_ldi, OP_INT, ap2, mk_reg(REG_R1));
        g_code(op_ldi, OP_INT, ap1, mk_reg(REG_R0));
      }
    } else {
      g_code(op_ldi, OP_INT, ap1, mk_reg(REG_R0));
      g_code(op_ldi, OP_INT, ap2, mk_reg(REG_R1));
    }
    if (is_signed == FALSE) {
      call_library_r0_r1(mod ? psup_ulrem : psup_uldiv);
    } else {
      call_library_r0_r1(mod ? psup_lrem : psup_ldiv);
    }
    return func_result(flags, 0L, ep->etp);
  case bt_float:
  case bt_double:
  case bt_longdouble:
    temp_inv();
    ap1 = g_expr(ep->v.p[0], F_FALL);
    ap2 = g_expr(ep->v.p[1], F_FALL);
    validate(ap1);
    freeop(ap2);
    freeop(ap1);
    if (ap2->preg == REG_R0) {
      /* bad luck, parameter is using space for ap1 */
      if (ap1->preg == REG_R1) {
        /* its worse, a2 is in r0 and a1 is in r1 */
        /* could be solved with parallel addressing */
        g_code(op_ldf, OP_INT, ap2, mk_freg(REG_R2));
        g_code(op_ldf, OP_INT, ap1, mk_freg(REG_R0));
        g_code(op_ldf, OP_INT, mk_freg(REG_R2), mk_freg(REG_R1));
      } else {
        g_code(op_ldf, OP_INT, ap2, mk_freg(REG_R1));
        g_code(op_ldf, OP_INT, ap1, mk_freg(REG_R0));
      }
    } else {
      g_code(op_ldf, OP_INT, ap1, mk_freg(REG_R0));
      g_code(op_ldf, OP_INT, ap2, mk_freg(REG_R1));
    }
    call_library_r0_r1(mod ? psup_lrem : psup_fpdiv);
    return func_result(flags, 0L, ep->etp);
  default:
    FATAL((__FILE__, "g_div", "%d: illegal type %d", mod, ep->etp->type));
    break;
  }
  return NIL_ADDRESS;
}

/*
 * generate /= and %= nodes.
 */
static ADDRESS *g_asdiv P3(const EXPR *, ep, FLAGS, flags, BOOL, mod) {
  switch (ep->etp->type) {
  case bt_char:
  case bt_schar:
  case bt_short:
  case bt_int16:
  case bt_int32:
  case bt_long:
    if (mod) {
      return as_fcall(ep, flags, psup_lrem, OP_INT);
    } else {
      return as_fcall(ep, flags, psup_ldiv, OP_INT);
    }
  case bt_charu:
  case bt_uchar:
  case bt_ushort:
  case bt_uint16:
  case bt_uint32:
  case bt_ulong:
  case bt_pointer32:
    if (mod) {
      return as_fcall(ep, flags, psup_ulrem, OP_INT);
    } else {
      return as_fcall(ep, flags, psup_uldiv, OP_INT);
    }
  case bt_float:
  case bt_double:
  case bt_longdouble:
    if (mod) {
      return as_fcall(ep, flags, psup_fprem, OP_FLOAT);
    } else {
      return as_fcall(ep, flags, psup_fpdiv, OP_FLOAT);
    }
  default:
    FATAL((__FILE__, "asdiv", "%d: illegal type %d", mod, ep->etp->type));
    break;
  }
  return NIL_ADDRESS;
}

/*============================================================================*/

static void g_inline_multiply P3(ADDRESS *, ap1, ADDRESS *, ap2, int, is_signed) {
  ADDRESS *ap3, *ap4, *ap5;

  ap3 = temporary_register(F_XREG);
  ap4 = temporary_register(F_XREG);
  if (is_signed == FALSE) {
    /* get signum */
    ap5 = temporary_register(F_XREG);
    /*
     * validates are not nescessary, since there must be enough
     * registers availlable, if not, this is a compilererror
     * and the validates will catch it and produce a fatal-error
     */
    validate(ap2);
    validate(ap1);
    g_code3(op_xor3, OP_INT, ap2, ap1, ap5);
    g_code(op_absi, OP_INT, ap1, ap1);
    g_code(op_absi, OP_INT, ap2, ap2);
  }
  g_code(op_ldi, OP_INT, mk_immed(-16), ap4);
  g_code3(op_lsh3, OP_INT, ap4, ap1, ap3);
  g_code3(op_lsh3, OP_INT, ap4, ap2, ap4);
  g_code(op_and, OP_INT, mk_uimmed(0xFFFFL), ap1);
  g_code(op_and, OP_INT, mk_uimmed(0XFFFFL), ap2);
  g_code(op_mpyi, OP_INT, ap1, ap4);
  g_code(op_mpyi, OP_INT, ap2, ap3);
  g_code(op_mpyi, OP_INT, ap1, ap2);
  g_code(op_addi, OP_INT, ap4, ap3);
  g_code(op_lsh, OP_INT, mk_immed(16), ap3);
  g_code3(op_addi3, OP_INT, ap3, ap2, ap1);
  if (is_signed == FALSE) {
    /* get signum */
    g_code(op_negi, OP_INT, ap1, ap2);
    g_code3(op_tstb3, OP_INT, ap5, ap5, NIL_ADDRESS);
    g_code(op_ldin, OP_INT, ap2, ap1);
    freeop(ap5);
  }
  freeop(ap4);
  freeop(ap3);
}

static ADDRESS *g_mul P2(const EXPR *, ep, FLAGS, flags) {
  int is_signed = TRUE;

  ADDRESS *ap1, *ap2, *ap3;

  switch (ep->etp->type) {
  case bt_uint32:
  case bt_ulong:
  case bt_pointer32:
    is_signed = FALSE;
    /*FALLTHRU */
  case bt_long:
  case bt_int32:
    if (opt_true_long != OPT_NO) {
      ap1 = g_expr(ep->v.p[0], (FLAGS)(F_VOL | best_flags(flags, F_XREG)));
      ap2 = g_expr(ep->v.p[1], (FLAGS)(F_VOL | F_XREG));
      validate(ap1);
      g_inline_multiply(ap1, ap2, is_signed);
      freeop(ap2);
      return mk_legal(ap1, flags, OP_INT);
    }
    /*FALLTHRU */
  case bt_char:
  case bt_schar:
  case bt_charu:
  case bt_uchar:
  case bt_short:
  case bt_int16:
  case bt_ushort:
  case bt_uint16:
    if (is_op3_possible(ep->v.p[0]) && is_op3_possible(ep->v.p[1])) {
      ap1 = g_expr(ep->v.p[0], (FLAGS)(F_XREG | F_MEM));
      ap2 = g_expr(ep->v.p[1], (FLAGS)(F_XREG | F_MEM));
      validate(ap1);
      /* Just to be sure... check again for correct op3-operands */
      if (is_op3_violated(ap1) || is_op3_violated(ap2)) {
        FATAL((__FILE__, "g_mul", "inconsistency int "));
      }
      freeop(ap2);
      freeop(ap1);
      ap3 = temporary_register(best_flags(flags, F_XREG));
      g_code3(op_mpyi3, OP_INT, ap2, ap1, ap3);
      ap1 = ap3;
    } else {
      if (tst_iconst(ep->v.p[0])) {
        ap1 = g_expr(ep->v.p[1], (FLAGS)(F_VOL | best_flags(flags, F_XREG)));
        ap2 = g_expr(ep->v.p[0], F_IALL);
      } else {
        ap1 = g_expr(ep->v.p[0], (FLAGS)(F_VOL | best_flags(flags, F_XREG)));
        ap2 = g_expr(ep->v.p[1], F_IALL);
      }
      validate(ap1); /* in case push occurred */
      g_code(op_mpyi, OP_INT, ap2, ap1);
      freeop(ap2);
    }
    return mk_legal(ap1, flags, OP_INT);
  case bt_float:
  case bt_double:
  case bt_longdouble:

    if (is_op3_possible(ep->v.p[0]) && is_op3_possible(ep->v.p[1])) {
      ap1 = g_expr(ep->v.p[0], (FLAGS)(F_FREG | F_MEM));
      ap2 = g_expr(ep->v.p[1], (FLAGS)(F_FREG | F_MEM));
      validate(ap1);
      /* Just to be sure... check again for correct op3-operands */
      if (is_op3_violated(ap1) || is_op3_violated(ap2)) {
        FATAL((__FILE__, "g_mul", "inconsistency float "));
      }
      freeop(ap2);
      freeop(ap1);
      ap3 = temporary_register(F_FREG);
      g_code3(op_mpyf3, OP_FLOAT, ap2, ap1, ap3);
      ap1 = ap3;
    } else {
      if (ep->v.p[0]->nodetype == en_fcon) {
        ap1 = g_expr(ep->v.p[1], (FLAGS)(F_VOL | F_FREG));
        ap2 = g_expr(ep->v.p[0], F_FALL);
      } else {
        ap1 = g_expr(ep->v.p[0], (FLAGS)(F_VOL | F_FREG));
        ap2 = g_expr(ep->v.p[1], F_FALL);
      }
      validate(ap1); /* in case push occurred */
      g_code(op_mpyf, OP_FLOAT, ap2, ap1);
      freeop(ap2);
    }
    return mk_legal(ap1, flags, OP_FLOAT);
  default:
    FATAL((__FILE__, "g_mul", "illegal type %d", ep->etp->type));
    break;
  }
  return NIL_ADDRESS;
}

/*
 * generate a *= node.
 */
static ADDRESS *g_asmul P2(const EXPR *, ep, FLAGS, flags) {
  int is_signed = TRUE;
  ADDRESS *ap1, *ap2, *ap3, *ap6;

  switch (ep->etp->type) {
  case bt_int32:
  case bt_long:
    is_signed = FALSE;
    /*FALLTHRU */
  case bt_uint32:
  case bt_ulong:
  case bt_pointer32:
    if (opt_true_long != OPT_NO) {
      if (ep->v.p[0]->nodetype == en_fieldref)
        return g_asbitfield(ep, flags, op_mpyi, FALSE);
      ap1 = g_expr(ep->v.p[0], (FLAGS)(F_IALL | F_USES));
      ap2 = g_expr(ep->v.p[1], (FLAGS)(F_XREG | F_VOL));
      if (isanyreg(ap1)) {
        validate(ap1);
        ap6 = NULL;
      } else {
        ap6 = ap1;
        ap1 = temporary_register(F_XREG);
        validate(ap6);
        g_code(op_ldi, OP_INT, ap6, ap1);
      }
      validate(ap2);
      g_inline_multiply(ap1, ap2, is_signed);
      if (ap6 != NULL) {
        freeop(ap1);
        validate(ap6);
        g_code(op_sti, OP_INT, ap1, ap6);
        ap1 = ap6;
      }
      freeop(ap2);
      return mk_legal(ap1, flags, OP_INT);
    }
    /*FALLTHRU */
  case bt_char:
  case bt_schar:
  case bt_charu:
  case bt_uchar:
  case bt_short:
  case bt_int16:
  case bt_ushort:
  case bt_uint16:
    if (ep->v.p[0]->nodetype == en_fieldref)
      return g_asbitfield(ep, flags, op_mpyi, FALSE);
    ap1 = g_expr(ep->v.p[0], (FLAGS)(F_IALL | F_USES));
    ap2 = g_expr(ep->v.p[1], (FLAGS)(F_IALL));
    if (isanyreg(ap1)) {
      validate(ap1);
      g_code(op_mpyi, OP_INT, ap2, ap1);
      freeop(ap2);
    } else {
      ap3 = temporary_register(F_XREG);
      validate(ap1);
      g_code(op_ldi, OP_INT, ap1, ap3);
      g_code(op_mpyi, OP_INT, ap2, ap3);
      g_code(op_sti, OP_INT, ap3, ap1);
      freeop(ap3);
      freeop(ap2);
    }
    return mk_legal(ap1, flags, OP_INT);
  case bt_float:
  case bt_double:
  case bt_longdouble:
    ap1 = g_expr(ep->v.p[0], (FLAGS)(F_FREG | F_MEM | F_IMMED | F_USES));
    ap2 = g_expr(ep->v.p[1], (FLAGS)(F_FREG | F_MEM | F_IMMED));
    if ((ap1->mode != am_freg)) {
      ap3 = data_register(F_FREG);
      validate(ap1);
      g_code(op_ldf, OP_FLOAT, ap1, ap3);
      g_code(op_mpyf, OP_FLOAT, ap2, ap3);
      g_code(op_stf, OP_FLOAT, ap3, ap1);
      freeop(ap3);
      freeop(ap2);
    } else {
      validate(ap1);
      g_code(op_mpyf, OP_FLOAT, ap2, ap1);
      freeop(ap2);
    }
    return mk_legal(ap1, flags, OP_FLOAT);
  default:
    FATAL((__FILE__, "asmul", "illegal type %d", ep->etp->type));
    break;
  }
  return NIL_ADDRESS;
}

/*============================================================================*/

/*
 * generate code to evaluate a condition operator node (?:)
 */
static ADDRESS *g_hook P2(const EXPR *, ep, FLAGS, flags) {
  ADDRESS *ap1, *ap2;
  EXPRTYPE typ1, typ2;
  FLAGS flagx;
  BOOL result_is_void = FALSE;
  ITYPE type = OP_INT;
  SIZE offset;
  LABEL false_label = nextlabel++;
  LABEL end_label = nextlabel++;

  switch (ep->etp->type) {
  case bt_void:
    result_is_void = TRUE;
    flagx = (FLAGS)(F_ALL | F_NOVALUE);
    break;
  case bt_float:
  case bt_double:
  case bt_longdouble:
    flagx = (FLAGS)(F_FREG | F_VOL);
    type = OP_FLOAT;
    break;
  default:
    flagx = (FLAGS)(best_flags(flags, F_XREG) | F_VOL);
    break;
  }

  typ1 = ep->v.p[1]->v.p[0]->nodetype;
  typ2 = ep->v.p[1]->v.p[1]->nodetype;
  if (((typ1 == en_autocon) || (typ1 == en_fcon) || (typ1 == en_register) || (is_short(ep->v.p[1]->v.p[0])) ||
       ((opt_const_in_ram != OPT_NO) && (typ1 == en_icon))) &&
      ((typ2 == en_autocon) || (typ2 == en_fcon) || (typ2 == en_register) || (is_short(ep->v.p[1]->v.p[1])) ||
       ((opt_const_in_ram != OPT_NO) && (typ2 == en_icon))) &&
      (ep->v.p[0]->nodetype != en_land) && (ep->v.p[0]->nodetype != en_lor)) {

    /* Sequence of ap1 and ap2 is important, validate is used in */
    /* routine g_conditionalload                                 */

    ap1 = g_expr(ep->v.p[1]->v.p[0], (type == OP_INT) ? F_IALL : F_FALL);
    ap2 = g_expr(ep->v.p[1]->v.p[1], (type == OP_INT) ? F_IALL : F_FALL);
    if (((ap1->mode == am_dreg) && is_temporary_register(ap1->preg)) ||
        ((ap2->mode == am_dreg) && is_temporary_register(ap2->preg))) {
      FATAL((__FILE__, "g_hook", "INCONSISTENCY Dreg"));
    }
    ap2 = g_conditionalload(ep->v.p[0], ap1, ap2, type, flagx);
  } else {
    temp_inv(); /* I do not think I can avoid that */
    offset = stack_offset;
    stack_offset = 0L;

    /* all scratch registers are void */

    g_falsejp(ep->v.p[0], false_label);
    ep = ep->v.p[1];

    /* all scratch registers are void */

    ap1 = g_expr(ep->v.p[0], flagx);
    freeop(ap1);

    /* all scratch registers are void */

    g_branch(end_label);
    g_label(false_label);

    ap2 = g_expr(ep->v.p[1], flagx);
    if (!result_is_void && !is_equal_address(ap1, ap2))
      FATAL((__FILE__, "g_hook", "INCONSISTENCY"));

    g_label(end_label);

    g_stack(stack_offset);
    stack_offset = offset;
  }
  return mk_legal(ap2, flags, type);
}

/*
 * rotate a bitfield into the required position (assumes ap is in a register)
 * Offset determines direction of shift, >= 0 bitfield is isolated and shiftet
 * to left, signum is maintained through combination lsh <<, ash >>
 *
 * Offset < 0 Bitfield is shifted to right, extrabits are not masked out
 */
static void g_rotate P4(ADDRESS *, ap, int, offset, TYP *, tp, int, width) {
  int w;

  if (offset >= 0) {
    switch (tp->type) {
    case bt_char:
    case bt_schar:
    case bt_short:
    case bt_int16:
    case bt_int32:
    case bt_long:
      /* signed bitfield */
      w = (int)(32 - offset - width);
      if (w != 0) {
        g_immed(op_lsh, (long)w, ap);
      }
      w = (int)(32 - width);
      if (w != 0) {
        g_immed(op_ash, (long)-w, ap);
      }
      break;

    default:
      /* unsigned bitfield */
      /* shift has same costs as and, thanks barrelshifter */
      if ((offset == 0) && (width <= 16)) {
        g_uimmed(op_and, bitmask(width), ap);
      } else {
        w = (int)(32 - offset - width);
        if (w != 0) {
          g_immed(op_lsh, (long)w, ap);
        }
        w = (int)(32 - width);
        if (w != 0) {
          g_immed(op_lsh, (long)-w, ap);
        }
      }
      break;
    }
  } else {
    FATAL((__FILE__, "g_rotate", "negative offset"));
    g_immed(op_lsh, (long)offset, ap);
  }
}

/*
 * generate the code for assign operators in bitfield
 * Swap determines 1 by divide if modulo or div is wished,
 * by ++/-- if posttype or pre-type (returns modified or standardvalue)
 */
static ADDRESS *g_asbitfield P4(const EXPR *, ep, FLAGS, flags, OPCODE, op, BOOL, postoperation) {
#ifdef NEW_BITFIELDSTUFF
  ADDRESS *ap5;

#endif
  ADDRESS *ap1, *ap2, *ap3, *ap4;
  EXPR *ep1, *lnode = ep->v.p[0];
  int width = (int)lnode->v.bit.width;
  int offset = (int)lnode->v.bit.offset;
  UVAL mask;

#ifdef NEW_BITFIELDSTUFF
  if ((flags & F_NOVALUE) == F_NONE) {
    ap5 = temporary_register(best_flags(flags, F_XREG));
  }
#endif
  ap4 = temporary_register(F_XREG);
  /* Evaluate the address of the LHS */
  ep1 = mk_ref(lnode->v.p[0], tp_pointer);
  ap2 = g_expr(ep1, F_MEM);

  /* Now get the value of the LHS, rotate and mask out unwanted bits */
  ap1 = temporary_register(F_XREG);

  g_code(op_ldi, OP_INT, ap2, ap1);
  /* Save the readed value for write back */

  validate(ap4);
  g_code(op_ldi, OP_INT, ap1, ap4);

  g_rotate(ap1, offset, lnode->etp, width);
#ifdef NEW_BITFIELDSTUFF
  if (((flags & F_NOVALUE) == F_NONE) && (postoperation)) {
    validate(ap5);
    g_code(op_ldi, OP_INT, ap1, ap5);
  }
#endif
  /* evaluate the RHS */
  ap3 = g_expr(ep->v.p[1], (FLAGS)(F_XREG | F_IMMED));
  validate(ap1);
  validate(ap2);

  /* now do the operation, masking the result back to the required size */
  switch (op) {
  case op_divs:
  case op_divu:
    FATAL((__FILE__, "g_asbitfield", "div is illegal"));
    break;
  default:
    g_code(op, OP_INT, ap3, ap1);
    break;
  }
  freeop(ap3);
#ifdef NEW_BITFIELDSTUFF
  if ((width + offset) <= 15) {
    ap3 = mk_immed(bitmask(width));
  } else {
#endif
    ap3 = temporary_register(F_XREG);
    if (width <= 15) {
      /* must be less than 16 bit sinc ldi immed is signed */
      mask = bitmask(width);
      g_immed(op_ldi, mask, ap3);
    } else {
      g_code(op_ldi, OP_INT, mk_immed(-1L), ap3);
      g_immed(op_lsh, -(32 - width), ap3);
    }
#ifdef NEW_BITFIELDSTUFF
  }
#endif

  validate(ap4);
#ifdef NEW_BITFIELDSTUFF
  if (((flags & F_NOVALUE) == F_NONE) && (!postoperation)) {
    /*
     * mask out the wanted bits and shift to correct position
     * and make a copy with correct sign as returnvalue (ap5)
     */
    validate(ap5);
    g_immed(op_lsh, (32 - width), ap1);
    g_code(op_ldi, OP_INT, ap1, ap5);
    if (is_signed_type(lnode->etp)) {
      g_immed(op_ash, -(32 - width), ap5);
    } else {
      g_immed(op_lsh, -(32 - width), ap5);
    }
    g_immed(op_lsh, -(32 - width - offset), ap1);
    if (offset != 0) {
      if ((width + offset) <= 15) {
        freeop(ap3);
        ap3 = mk_immed(bitmask(width) << offset);
      } else {
        g_immed(op_lsh, offset, ap3);
      }
    }
  } else {
    /* mask out the wanted bits and shift to correct position */
    g_code(op_and, OP_INT, ap3, ap1);
    if (offset != 0) {
      g_immed(op_lsh, offset, ap1);
      if ((width + offset) <= 15) {
        freeop(ap3);
        ap3 = mk_immed(bitmask(width) << offset);
      } else {
        g_immed(op_lsh, offset, ap3);
      }
    }
  }
#else
  g_code(op_and, OP_INT, ap3, ap1);
  if (offset != 0) {
    g_immed(op_lsh, offset, ap1);
    g_immed(op_lsh, offset, ap3);
  }
#endif
  validate(ap4);
  g_code(op_andn, OP_INT, ap3, ap4);
  g_code(op_or, OP_INT, ap1, ap4);
  g_code(op_sti, OP_INT, ap4, ap2);

  freeop(ap3);
  freeop(ap1);
  freeop(ap2);
  freeop(ap4);

#ifdef NEW_BITFIELDSTUFF
  if ((flags & F_NOVALUE) == F_NONE) {
    validate(ap5);
    ap1 = ap5;
  } else {
    ap1 = NIL_ADDRESS;
  }

#else
  /* return a result */
  ap2 = temporary_register(F_XREG);
  g_code(op_ldi, OP_INT, ap1, ap2);
  ap1 = ap2;

  if ((flags & F_NOVALUE) == F_NONE) {
    /* result value needed */
    /* get value with correct sign */
    g_rotate(ap1, offset, lnode->etp, width);
    if (postoperation) {
      /* post increment/decrement restore original value */
      switch (op) {
      case op_addi:
        op = op_subi;
        g_code(op, OP_INT, mk_immed(1L), ap1);
        /* get value with correct sign and significant bits */
        g_rotate(ap1, 0, lnode->etp, width);
        break;
      case op_subi:
        op = op_addi;
        g_code(op, OP_INT, mk_immed(1L), ap1);
        /* get value with correct sign and significant bits */
        g_rotate(ap1, 0, lnode->etp, width);
        break;
      default:
        break;
      }
    }
  }
#endif
  return mk_legal(ap1, flags, OP_INT);
}

/*
 * assign structure from ap1 to ap2
 * ap1, ap2 are scratch address registers
 */
static void structassign P3(ADDRESS *, ap1, ADDRESS *, ap2, SIZE, size) {
  SIZE loop;
  ADDRESS *ap3;
  SIZE i;

  if (size == 0L) {
    FATAL((__FILE__, "structassign", "size = 0"));
  }
  loop = size;
  ap1 = copy_addr(ap1, am_ainc);
  ap1->u.offset = mk_const(1);
  ap2 = copy_addr(ap2, am_ainc);
  ap2->u.offset = mk_const(1);
  ap3 = data_register(F_DREG);

  /* Fetch first word to init prallelmode */
  g_code(op_ldi, OP_INT, ap1, ap3);

  /* Short loops we do manually */
  if (loop <= 3) {
    for (i = 1; i <= loop - 1; i++) {
      g_code_parallel(op_ldi_sti, OP_INT, ap1, NIL_ADDRESS, ap3, ap3, NIL_ADDRESS, ap2);
    }
  } else {
    /* check if we have to save the blockrepeatregisters */
#if 0
	save_blockrepeat ();	/* for dbra */
#endif
    allocate_blockrepeat_registers();
    /* repeat copy instruction loop-2 times */
    g_uimmed(op_rpts, loop - 2, NIL_ADDRESS);
    g_code_parallel(op_ldi_sti, OP_INT, ap1, NIL_ADDRESS, ap3, ap3, NIL_ADDRESS, ap2);
#if 0
	restore_blockrepeat ();
#endif
  }
  /* finish the last cycle */
  g_code(op_sti, OP_INT, ap3, ap2);
  freeop(ap3);
}

/*
 * generate code for an assignment node.
 */
static ADDRESS *g_assign P2(const EXPR *, ep, FLAGS, flags) {
  ADDRESS *ap1, *ap2, *ap3, *ap4;
  EXPR *ep1;
  TYP *tp = ep->etp;
  SIZE size = ep->etp->size;
  ITYPE type = OP_INT;
  UVAL mask;
  FLAGS flagf, flagi;

  flagf = (flags & F_NOVALUE) ? F_FALL : (FLAGS)(F_FALL | F_USES);
  flagi = (flags & F_NOVALUE) ? F_IALL : (FLAGS)(F_IALL | F_USES);
  switch (tp->type) {
  case bt_pointer32:
    if (!is_array_type(tp) && !is_array_assignment(tp)) {
      goto common;
    }
    /*FALLTHRU */
  case bt_struct:
  case bt_union:
    /*
     * Other parts of this module return a pointer to a struct in a register,
     * not the struct itself
     */
    ap1 = g_expr(ep->v.p[1], (FLAGS)(F_AREG | F_VOL));
    ap2 = g_expr(ep->v.p[0], (FLAGS)(F_AREG | F_VOL));
    validate(ap1);

    /* hacky: save ap1 if needed later, structassign destroys it */
    if (flags & F_NOVALUE) {
      /* no need to save any registers */
      structassign(ap1, ap2, ep->etp->size);
      freeop(ap2);
      freeop(ap1);
      return NIL_ADDRESS;
    }
    ap3 = address_register();
    g_code(op_ldi, OP_INT, ap1, ap3);
    structassign(ap3, ap2, size);
    freeop(ap3);
    freeop(ap2);
    validate(ap1);
    return mk_legal(ap1, flags, OP_INT);

  case bt_float:
  case bt_double:
  case bt_longdouble:
    switch (ep->v.p[0]->nodetype) {
    case en_fieldref:
      FATAL((__FILE__, "g_assign", "en_fieldref for float"));
      /*NOTREACHED */

      /*
       * we want to pass the right hand side as the expression value.
       * This can''t be done if the left side is a register variable
       * on which the right hand side addressing mode depends. But if
       * the left side IS a register variable, it is desirable to pass
       * the left side, so no problem.
       */

    case en_register:
      /* pass the left side as expr. value */
      ap1 = g_expr(ep->v.p[0], flagf);
      ap2 = g_expr(ep->v.p[1], F_FALL);
      validate(ap1);
      switch (ap1->mode) {
      case am_areg:
      case am_dreg:
      case am_ireg:
      case am_sreg:
        FATAL((__FILE__, "g_assign", "Integer mixed with float"));
        break;
      case am_freg:
        g_code(op_ldf, OP_FLOAT, ap2, ap1);
        type = OP_FLOAT;
        break;
      default:
        switch (ap2->mode) {
        case am_areg:
        case am_dreg:
        case am_ireg:
        case am_sreg:
          FATAL((__FILE__, "g_assign", "Integer mixed with float"));
          break;
        case am_freg:
          g_code(op_stf, OP_FLOAT, ap2, ap1);
          type = OP_FLOAT;
          break;
        default:
          /* we can not store memory to memory directly */
          ap3 = temporary_register(F_FREG);
          g_code(op_ldf, OP_FLOAT, ap2, ap3);
          g_code(op_stf, OP_FLOAT, ap3, ap1);
          type = OP_FLOAT;
          freeop(ap3);
          break;
        }
        break;
      }
      freeop(ap2);
      return mk_legal(ap1, flags, OP_FLOAT);

    default:
      /* pass the right side as expr. value */
      /* normally, this is more efficient */
      ap1 = g_expr(ep->v.p[1], flagf);
      ap2 = g_expr(ep->v.p[0], F_FALL);
      validate(ap1);
      switch (ap2->mode) {
      case am_areg:
      case am_dreg:
      case am_ireg:
      case am_sreg:
        FATAL((__FILE__, "g_assign", "Integer mixed with float"));
        break;
      case am_freg:
        g_code(op_ldf, OP_FLOAT, ap1, ap2);
        type = OP_FLOAT;
        break;
      default:
        switch (ap1->mode) {
        case am_areg:
        case am_dreg:
        case am_ireg:
        case am_sreg:
          FATAL((__FILE__, "g_assign", "Integer mixed with float"));
          break;
        case am_freg:
          type = OP_FLOAT;
          g_code(op_stf, OP_FLOAT, ap1, ap2);
          break;
        default:
          /* we can not store memory to memory directly */
          ap3 = temporary_register(F_FREG);
          g_code(op_ldf, OP_FLOAT, ap1, ap3);
          g_code(op_stf, OP_FLOAT, ap3, ap2);
          freeop(ap3);
          break;
        }
        break;
      }
      freeop(ap2);
      return mk_legal(ap1, flags, type);
    }

  default:
  common:
    switch (ep->v.p[0]->nodetype) {
    case en_fieldref:
      /*
       * Field assignment
       */
      /* get the value */
      mask = bitmask(ep->v.p[0]->v.bit.width);
      ap1 = g_expr(ep->v.p[1], (FLAGS)(F_IMMED | F_XREG | F_VOL));
      if (ap1->mode == am_immed) {
        ap1->u.offset->v.i &= mask;
        ap3 = mk_uimmed((ap1->u.offset->v.i) << ep->v.p[0]->v.bit.offset);
      } else {
        if (flags & F_NOVALUE) {
          g_uimmed(op_and, mask, ap1);
          ap3 = ap1;
          if (ep->v.p[0]->v.bit.offset != 0) {
            g_immed(op_lsh, ep->v.p[0]->v.bit.offset, ap3);
          }
        } else {
          /*
           * mask out the wanted bits and shift to correct position
           * and make a copy with correct sign as returnvalue (ap5)
           */
          g_immed(op_lsh, (32 - ep->v.p[0]->v.bit.width), ap1);
          ap3 = temporary_register(F_XREG);
          g_code(op_ldi, OP_INT, ap1, ap3);
          if (is_signed_type(tp)) {
            g_immed(op_ash, -(32 - ep->v.p[0]->v.bit.width), ap1);
          } else {
            g_immed(op_lsh, -(32 - ep->v.p[0]->v.bit.width), ap1);
          }
          g_immed(op_lsh, -(32 - ep->v.p[0]->v.bit.width - ep->v.p[0]->v.bit.offset), ap3);
        }
      }
      mask <<= ep->v.p[0]->v.bit.offset;
      ep1 = mk_ref(ep->v.p[0]->v.p[0], tp_pointer);
      ap2 = g_expr(ep1, F_MEM);
      validate(ap3);
      ap4 = temporary_register(F_XREG);
      g_code(op_ldi, OP_INT, ap2, ap4);
      g_uimmed(op_andn, mask, ap4);
      g_code(op_or, OP_INT, ap3, ap4);
      g_code(op_sti, OP_INT, ap4, ap2);
      freeop(ap4);
      freeop(ap2);
      if (!(flags & F_NOVALUE)) {
        freeop(ap3);
        validate(ap1);
      }
      return mk_legal(ap1, flags, OP_INT);

      /*
       * we want to pass the right hand side as the expression value.
       * This can''t be done if the left side is a register variable
       * on which the right hand side addressing mode depends. But if
       * the left side IS a register variable, it is desirable to pass
       * the left side, so no problem.
       */
    case en_register:
      /* pass the left side as expr. value */
      ap1 = g_expr(ep->v.p[0], flagi);
      ap2 = g_expr(ep->v.p[1], F_IALL);
      validate(ap1);
      switch (ap1->mode) {
      case am_areg:
      case am_dreg:
      case am_ireg:
      case am_sreg:
        g_code(op_ldi, OP_INT, ap2, ap1);
        break;
      case am_freg:
        FATAL((__FILE__, "g_assign", "Float mixed with integer"));
        break;
      default:
        switch (ap2->mode) {
        case am_areg:
        case am_dreg:
        case am_ireg:
        case am_sreg:
          g_code(op_sti, OP_INT, ap2, ap1);
          break;
        case am_freg:
          FATAL((__FILE__, "g_assign", "Float mixed with integer"));
          break;
        default:
          /* we can not store memory to memory directly */
          ap3 = temporary_register(F_XREG);
          g_code(op_ldi, OP_INT, ap2, ap3);
          g_code(op_sti, OP_INT, ap3, ap1);
          freeop(ap3);
          break;
        }
        break;
      }
      freeop(ap2);
      return mk_legal(ap1, flags, OP_INT);
    default:
      /* pass the right side as expr. value */
      /* normally, this is more efficient */
      ap1 = g_expr(ep->v.p[1], flagi);
      ap2 = g_expr(ep->v.p[0], F_IALL);
      validate(ap1);
      switch (ap2->mode) {
      case am_areg:
      case am_dreg:
      case am_ireg:
      case am_sreg:
        g_code(op_ldi, OP_INT, ap1, ap2);
        break;
      case am_freg:
        FATAL((__FILE__, "g_assign", "Float mixed with integer"));
        break;
      default:
        switch (ap1->mode) {
        case am_areg:
        case am_dreg:
        case am_ireg:
        case am_sreg:
          g_code(op_sti, OP_INT, ap1, ap2);
          break;
        case am_freg:
          FATAL((__FILE__, "g_assign", "Float mixed with integer"));
          break;
        default:
          /* we can not store memory to memory directly */
          ap3 = temporary_register(F_XREG);
          g_code(op_ldi, OP_INT, ap1, ap3);
          g_code(op_sti, OP_INT, ap3, ap2);
          freeop(ap3);
          break;
        }
        break;
      }
      freeop(ap2);
      return mk_legal(ap1, flags, type);
    }
  }
  return NIL_ADDRESS;
}

/*
 * push the operand expression onto the stack. return the number of bytes
 * pushed
 */
static SIZE push_param P1(const EXPR *, ep) {
  ADDRESS *ap, *ap1;
  SIZE size = ep->etp->size;

  /* pushing of structures and unions */
  switch (ep->etp->type) {
  case bt_struct:
  case bt_union:
    if (is_lvalue(ep)) {
      ep = ep->v.p[0];
    }
    /* all other cases return a pointer to the struct anyway */
    /* allocate stack space */
    ap1 = address_register();
    g_code(op_ldi, OP_INT, mk_reg(STACKPTR), ap1);
    /*
     * Add 1 to pointer sinc sp points allways to top-of-stack
     * next free location on stack is sp-1
     */
    g_code(op_addi, OP_INT, mk_immed(1), ap1);

    g_immed(op_addi, size, mk_reg(STACKPTR));
    /*
     * F_VOL was missing in the following line --
     * it took a hard-core debugging session to find this error
     */
    ap = g_expr(ep, (FLAGS)(F_AREG | F_VOL));
    validate(ap1);
    /* now, copy it on stack - the same as structassign */
    structassign(ap, ap1, size);
    freeop(ap);
    freeop(ap1);
    break;
  case bt_float:
  case bt_double:
  case bt_longdouble:
    ap = g_expr(ep, F_FREG);
    g_code(op_pushf, OP_FLOAT, ap, NIL_ADDRESS);
    freeop(ap);
    break;
  default:
    ap = g_expr(ep, F_XREG);
    g_code(op_push, OP_INT, ap, NIL_ADDRESS);
    freeop(ap);
    break;
  }
  return size;
}

/*
 * push a list of parameters onto the stack and return the number of
 * bytes that they occupy on the stack.
 */
static SIZE g_parms P1(const EXPR *, plist) {
  SIZE size;

  is_parameter++;
  for (size = 0L; plist != NIL_EXPR; plist = plist->v.p[1]) {
    size += push_param(plist->v.p[0]);
  }
  is_parameter--;
  return size;
}

/*
 * saves a function call result in D0 it is assumed that flags contain
 * either F_DREG or F_AREG. return value is the addressing mode of the
 * result bytes is the number of bytes to pop off the stack
 *
 * This routine does not use mk_legal and takes care of the stuff itself.
 */
static ADDRESS *func_result P3(FLAGS, flags, SIZE, bytes, TYP *, tp) {
  ADDRESS *ap;

  stack_offset += bytes;
  if (is_parameter)
    g_stack(bytes);
  if (flags & F_NOVALUE)
    return NIL_ADDRESS;
  switch (tp->type) {
  case bt_float:
  case bt_double:
  case bt_longdouble:
    if (flags & F_FREG) {
      ap = data_register(F_FREG);
      g_code(op_ldf, OP_FLOAT, mk_freg(RESULT), ap);
    } else {
      FATAL((__FILE__, "func_result", "illegal addressing mode"));
    }
    break;
  default:
    if (flags & F_XREG) {
      ap = temporary_register((FLAGS)(flags & F_XREG));
      g_code(op_ldi, OP_INT, mk_reg(RESULT), ap);
    } else {
      FATAL((__FILE__, "func_result", "illegal addressing mode"));
    }
    break;
  }
  return ap;
}

/* assignment operations with library calls */
/*
 * Attention, parameters and returnvalue are assumed to be of the
 * same type (either OP_FLOAT or OP_INT)
 *
 */
static ADDRESS *as_fcall P4(const EXPR *, ep, FLAGS, flags, const CHAR *, libnam1, ITYPE, type) {
  /*
   * example: libnam1 = ".ldiv"
   */
  ADDRESS *ap1, *ap2, *ap3, *ap4;
  EXPR *lnode;
  UVAL mask;
  int width, offset;

  temp_inv();
  switch (ep->v.p[0]->nodetype) {
  case en_register:
    ap2 = g_expr(ep->v.p[1], (type == OP_INT) ? F_IALL : F_FALL);

    /* ap1 cannot be destroyed, no problem */
    ap1 = g_expr(ep->v.p[0], (FLAGS)(F_XREG | F_FREG));
    validate(ap2);
    freeop(ap2);
    /* no problem at all, ap1 can't be in R1 (tempref!) */
    if (type == OP_INT) {
      g_code(op_ldi, OP_INT, ap2, mk_reg(REG_R1));
      g_code(op_ldi, OP_INT, ap1, mk_reg(REG_R0));
    } else {
      g_code(op_ldf, OP_FLOAT, ap2, mk_freg(REG_R1));
      g_code(op_ldf, OP_FLOAT, ap1, mk_freg(REG_R0));
    }
    call_library_r0_r1(libnam1);
    /* ap1 is always valid and not equal to RESULT */
    if (type == OP_INT) {
      g_code(op_ldi, OP_INT, mk_reg(RESULT), ap1);
    } else {
      g_code(op_ldf, OP_FLOAT, mk_freg(RESULT), ap1);
    }
    break;
  case en_fieldref:
    lnode = ep->v.p[0];
    width = (int)lnode->v.bit.width;
    offset = (int)lnode->v.bit.offset;

    /* evaluate the address of the LHS */
    ap3 = g_deref(lnode->v.p[0], lnode->etp, F_MEM);
    freeop(ap3);
    switch (ap3->mode) {
    case am_indx:
      ap3 = copy_addr(ap3, am_areg);
      ap2 = ap3;
      if (!is_temporary_register(ap3->preg)) {
        /* is tempref register, dont overwrite */
        ap2 = address_register();
        g_code(op_ldi, OP_INT, ap3, ap2);
      }
      g_immed(op_addi, ap3->u.offset->v.i, ap2);
      break;
    case am_indx2:
      ap3 = copy_addr(ap3, am_areg);
      ap2 = ap3;
      if (!is_temporary_register(ap3->preg)) {
        /* is tempref register, dont overwrite */
        ap2 = address_register();
        g_code(op_ldi, OP_INT, ap3, ap2);
      }
      g_code(op_addi, OP_INT, mk_reg(ap3->sreg), ap2);
      break;
    case am_indxs:
      ap3 = copy_addr(ap3, am_areg);
      ap2 = ap3;
      if (!is_temporary_register(ap3->preg)) {
        /* is tempref register, dont overwrite */
        ap2 = address_register();
        g_code(op_ldi, OP_INT, ap3, ap2);
      }
      g_code(op_subi, OP_INT, mk_reg(ap3->sreg), ap2);
      break;
    case am_ind:
    case am_const_ind:
      if (is_temporary_register(ap3->preg)) {
        ap3 = copy_addr(ap3, am_areg);
      }
      ap2 = ap3;
      break;
    case am_direct:
      ap3 = copy_addr(ap3, am_direct);
      ap2 = ap3;
      break;
    case am_const_direct:
      ap3 = copy_addr(ap3, am_const_direct);
      ap2 = ap3;
      break;
    default:
      FATAL((__FILE__, "as_fcall", "illegal addressing mode"));
    }

    /* and save this address on the stack so that it can be used later */
    if ((ap3->mode != am_direct) && (ap3->mode != am_const_direct) && (ap3->mode != am_ind) && (ap3->mode != am_const_ind)) {
      /* a constant address must not be saved, it will not change */
      /* during an functionscall :-) */
      /* also a am_ind refering to a registervariable must not be saved */
      g_code(op_push, OP_INT, ap2, NIL_ADDRESS);
      ap2 = copy_addr(ap2, am_ind);
    }
    if (ap2 != ap3) {
      freeop(ap2);
    }
    /* Now get the value of the LHS */
    ap1 = temporary_register(best_flags(flags, F_XREG));
    g_code(op_ldi, OP_INT, ap2, ap1);

    /* evaluate the RHS and push it onto the stack */
    ap2 = g_expr(ep->v.p[1], F_XREG);
    validate(ap1);
    /* rotate to position, mask out unwanted bits */
    g_rotate(ap1, offset, lnode->etp, width);
    freeop(ap2);
    /* do not freeop(ap1), we use it later to store result in it */
    /* so it doesn't matter if it is overwritten due functinscall */

    if (ap2->preg == REG_R0) {
      /* bad luck, parameter is using space for ap1 */
      if (ap1->preg == REG_R1) {
        /* its worse, a2 is in r0 and a1 is in r1 */
        /* could be solved with parallel addressing */
        g_code(op_ldi, OP_INT, ap2, mk_reg(REG_R2));
        g_code(op_ldi, OP_INT, ap1, mk_reg(REG_R0));
        g_code(op_ldi, OP_INT, mk_reg(REG_R2), mk_reg(REG_R0));
      } else {
        g_code(op_ldi, OP_INT, ap2, mk_reg(REG_R1));
        g_code(op_ldi, OP_INT, ap1, mk_reg(REG_R0));
      }
    } else {
      g_code(op_ldi, OP_INT, ap1, mk_reg(REG_R0));
      g_code(op_ldi, OP_INT, ap2, mk_reg(REG_R1));
    }
    /* now do the operation, masking the result back to the required size */
    call_library_r0_r1(libnam1);

    /* ap1 points still to an register from above */
    g_code(op_ldi, OP_INT, mk_reg(RESULT), ap1);
    mask = bitmask(width);
    if (flags & F_NOVALUE) {
      g_uimmed(op_and, mask, ap1);
      ap4 = ap1;
      if (offset != 0) {
        g_immed(op_lsh, offset, ap4);
      }
    } else {
      /*
       * mask out the wanted bits and shift to correct position
       * and make a copy with correct sign as returnvalue (ap1)
       */
      g_immed(op_lsh, (32 - width), ap1);
#ifdef NEW_BITFIELDSTUFF
      ap4 = ap1;
      ap1 = temporary_register(F_XREG);
      g_code(op_ldi, OP_INT, ap4, ap1);
#else
      ap4 = temporary_register(F_XREG);
      g_code(op_ldi, OP_INT, ap1, ap4);
#endif
      if (is_signed_type(lnode->etp)) {
        g_immed(op_ash, -(32 - width), ap1);
      } else {
        g_immed(op_lsh, -(32 - width), ap1);
      }
      g_immed(op_lsh, -(32 - width - offset), ap4);
    }

    /* restore ap3 (ap3 is not used since push, so information */
    /* contained in it is still valid, only registers are */
    /* no more valid) */
    if ((ap3->mode != am_direct) && (ap3->mode != am_const_direct) && (ap3->mode != am_ind) && (ap3->mode != am_const_ind)) {
      ap3 = address_register();
      g_code(op_pop, OP_INT, NIL_ADDRESS, ap3);
      ap3 = copy_addr(ap3, am_ind);
    }
    ap2 = temporary_register(F_XREG);
    g_code(op_ldi, OP_INT, ap3, ap2);
    /* rotate result back into position, and store */
    mask <<= offset;
    g_uimmed(op_andn, mask, ap2);
    g_code(op_or, OP_INT, ap4, ap2);
    g_code(op_sti, OP_INT, ap2, ap3);
    freeop(ap2);
    freeop(ap3);
    if (!(flags & F_NOVALUE)) {
#ifdef NEW_BITFIELDSTUFF
      validate(ap4);
      validate(ap1);
      g_code(op_ldi, OP_INT, ap1, ap4);
      freeop(ap1);
      ap1 = ap4;
#else
      freeop(ap4);
      validate(ap1);
#endif
    }
    return mk_legal(ap1, flags, OP_INT);
  default:
    ap2 = g_expr(ep->v.p[1], (type == OP_INT) ? F_IALL : F_FALL);
    ap1 = g_expr(ep->v.p[0], (FLAGS)(F_IALL | F_USES));
    freeop(ap1);
    switch (ap1->mode) {
    case am_indx:
      ap1 = copy_addr(ap1, am_areg);
      ap3 = ap1;
      if (!is_temporary_register(ap1->preg)) {
        /* is tempref register, dont overwrite */
        ap3 = address_register();
        g_code(op_ldi, OP_INT, ap1, ap3);
        freeop(ap3);
      }
      g_immed(op_addi, ap1->u.offset->v.i, ap3);
      break;
    case am_indx2:
      ap1 = copy_addr(ap1, am_areg);
      ap3 = ap1;
      if (!is_temporary_register(ap1->preg)) {
        /* is tempref register, dont overwrite */
        ap3 = address_register();
        g_code(op_ldi, OP_INT, ap1, ap3);
        freeop(ap3);
      }
      g_code(op_addi, OP_INT, mk_reg(ap1->sreg), ap3);
      break;
    case am_indxs:
      ap1 = copy_addr(ap1, am_areg);
      ap3 = ap1;
      if (!is_temporary_register(ap1->preg)) {
        /* is tempref register, dont overwrite */
        ap3 = address_register();
        g_code(op_ldi, OP_INT, ap1, ap3);
        freeop(ap3);
      }
      g_code(op_subi, OP_INT, mk_reg(ap1->sreg), ap3);
      break;
    case am_ind:
    case am_const_ind:
      ap1 = copy_addr(ap1, am_areg);
      ap3 = ap1;
      break;
    case am_direct:
      ap1 = copy_addr(ap1, am_direct);
      ap3 = ap1;
      break;
    case am_const_direct:
      ap1 = copy_addr(ap1, am_const_direct);
      ap3 = ap1;
      break;
    default:
      FATAL((__FILE__, "as_fcall", "illegal addressing mode"));
    }
    /* and save this address on the stack so that it can be used later */
    if ((ap3->mode != am_direct) && (ap3->mode != am_const_direct)) {
      /* a constant address must not be saved, it will not change */
      /* during a function call :-) */
      g_code(op_push, OP_INT, ap3, NIL_ADDRESS);
      ap3 = copy_addr(ap3, am_ind);
    }
    validate(ap2);
    freeop(ap2);

    /* ap3 is an addressregister, so we can't overwrite it */
    if (type == OP_INT) {
      g_code(op_ldi, OP_INT, ap2, mk_reg(REG_R1));
      g_code(op_ldi, OP_INT, ap3, mk_reg(REG_R0));
    } else {
      g_code(op_ldf, OP_FLOAT, ap2, mk_freg(REG_R1));
      g_code(op_ldf, OP_FLOAT, ap3, mk_freg(REG_R0));
    }

    /* now do the operation  */
    call_library_r0_r1(libnam1);

    /* restore ap1 */
    if ((ap1->mode != am_direct) && (ap1->mode != am_const_direct)) {
      ap1 = address_register();
      g_code(op_pop, OP_INT, NIL_ADDRESS, ap1);
      ap1 = copy_addr(ap1, am_ind);
    }
    if (type == OP_INT) {
      g_code(op_sti, OP_INT, mk_reg(RESULT), ap1);
    } else {
      g_code(op_stf, OP_FLOAT, mk_freg(RESULT), ap1);
    }
    freeop(ap1);
    break;
  }
  if (flags & F_NOVALUE)
    return NIL_ADDRESS;

  if (type == OP_INT) {
    ap1 = temporary_register(best_flags(flags, F_XREG));
    g_code(op_ldi, OP_INT, mk_reg(RESULT), ap1);
  } else {
    ap1 = temporary_register(F_FREG);
    g_code(op_ldf, OP_FLOAT, mk_freg(RESULT), ap1);
  }
  return mk_legal(ap1, flags, type);
}

/*
 * generate a function call node and return the address mode of the result.
 */
static ADDRESS *g_fcall P2(const EXPR *, ep, FLAGS, flags) {
  EXPR *ep0 = ep->v.p[0];
  TYP *tp = ep->etp;
  ADDRESS *ap, *ap2;
  SIZE size;

  if (!is_parameter && ep->nodetype != en_call) {
    switch (stackopt_option) {

    case OPT_SAFE:
      g_stack(stack_offset);
      break;

    case OPT_MINIMUM:
      /*
       *       Perform a stack optimisation unless:
       *       1.  The function call is via a variable
       *       2.  The function starts with an underscore character
       *       3.  The alloca() routine is called
       */
      if ((ep0->nodetype != en_nacon) || (ep0->v.str[0] == (CHAR)'_') || (ep0->v.str == alloca_name)) {
        g_stack(stack_offset);
      }
      break;

    case OPT_AVERAGE:
      /*
       *       "Average" stack optimisation.   This will not suppress
       *       the optimisation on encountering calls to functions
       *       whose names begin with underscore.
       */
      if ((ep0->nodetype != en_nacon) || (ep0->v.str == alloca_name)) {
        g_stack(stack_offset);
      }
      break;

    case OPT_MAXIMUM:
      /*
       *       "Maximum" stack optimisation.   This will not suppress
       *       the optimisation on encountering calls to functions
       *       whose names begin with underscore or via a function
       *       variable.
       */
      if ((ep0->nodetype == en_nacon) && (ep0->v.str == alloca_name)) {
        g_stack(stack_offset);
      }
      break;

    default:
      CANNOT_REACH_HERE();
      break;
    }
  }
  /* push any used addr&data temps */
  temp_inv();
  size = g_parms(ep->v.p[1]); /* generate parameters */
  if (is_structure_type(tp)) {
    /*
     *   For functions returning a structure or a union, push
     *   a pointer to the return value as additional argument.
     *   The scratch space will be allocated in the stack frame
     *   of the calling function.
     */
    ap = mk_scratch(tp->size);
    ap = copy_addr(ap, am_areg);
    if (ap->u.offset->v.i != 0L) {
      freeop(ap);
      ap2 = temporary_register(F_XREG);
      g_code(op_ldi, OP_INT, ap, ap2);
      g_immed(op_addi, (long)ap->u.offset->v.i, ap2);
      ap = ap2;
    }
    g_code(op_push, OP_INT, ap, NIL_ADDRESS);
    size += tp_pointer->size;
    freeop(ap);
  }
  if (ep->nodetype == en_call) {
    size = 0L;
  }
  /* call the function */
  switch (ep0->nodetype) {
  case en_nacon:
    /*
     * if functionsname is __trap_nn, 00<=nn<=31
     * we generate a trapinstruction instaed of
     * call, may simplify interface to operatingsystem
     */
    ap = check_trap(ep0);
    if (ap != NIL_ADDRESS) {
      g_code(op_trapu, OP_INT, ap, NIL_ADDRESS);
      return func_result(flags, size, ep->etp);
    }
    /* FALLTHRU */
  case en_labcon:
    ap = mk_immediatelabel(ep0);
    break;
  default:
    ap = g_expr(ep0, F_XREG);
    freeop(ap);
    break;
  }
  if (ap->mode == am_immed) {
    g_code(op_call, OP_INT, ap, NIL_ADDRESS);
  } else {
    g_code(op_callu, OP_INT, ap, NIL_ADDRESS);
  }
  return func_result(flags, size, tp);
}

/*
 * generates code for a en_cast node
 *
 */
static ADDRESS *g_cast P4(ADDRESS *, ap, TYP *, tp1, TYP *, tp2, FLAGS, flags) {
  ADDRESS *ap1;

  if (flags & F_NOVALUE) {
    freeop(ap);
    return NIL_ADDRESS;
  }
  if (is_same_type(tp1, tp2)) {
    /*
     * this can happen in with the g_xmul stuff, where a cast from
     * (u)short to long now casts from (u)short to (u)short for an 68000
     * mulu or muls instruction.
     * It is save to cut things short then.
     * It should not happen with types other than (u)short, but
     * it does not harm either.
     */
    switch (tp1->type) {
    case bt_short:
    case bt_ushort:
    case bt_int16:
    case bt_uint16:
      return mk_legal(ap, flags, OP_INT);
    default:
      FATAL((__FILE__, "g_cast", "tp1==tp2 (%d)", tp1->type));
      break;
    }
  }
  switch (tp2->type) {
    /* switch: type to cast to */
  case bt_char:
  case bt_charu:
  case bt_schar:
  case bt_uchar:
  case bt_ushort:
  case bt_short:
  case bt_int16:
  case bt_uint16:
  case bt_int32:
  case bt_uint32:
  case bt_long:
  case bt_ulong:
  case bt_pointer32:
    switch (tp1->type) {
    case bt_charu:
    case bt_uchar:
    case bt_char:
    case bt_schar:
    case bt_ushort:
    case bt_uint16:
    case bt_short:
    case bt_int16:
    case bt_int32:
    case bt_uint32:
    case bt_long:
    case bt_ulong:
    case bt_pointer32:
      return mk_legal(ap, flags, OP_INT);
    case bt_float:
    case bt_double:
    case bt_longdouble:
      freeop(ap);
      ap1 = temporary_register(best_flags(flags, F_XREG));
      g_code(op_fix, OP_FLOAT, ap, ap1);
      ap = ap1;
      return mk_legal(ap, flags, OP_INT);
    default:
      break;
    }
    break;
  case bt_float:
  case bt_double:
  case bt_longdouble:
    switch (tp1->type) {
    case bt_char:
    case bt_charu:
    case bt_schar:
    case bt_uchar:
    case bt_short:
    case bt_ushort:
    case bt_int16:
    case bt_uint16:
    case bt_int32:
    case bt_uint32:
    case bt_long:
    case bt_ulong:
    case bt_pointer32:
      freeop(ap);
      ap1 = data_register(F_FREG);
      g_code(op_float, OP_INT, ap, ap1);
      ap = ap1;
      return mk_legal(ap, flags, OP_FLOAT);
    case bt_float:
    case bt_double:
    case bt_longdouble:
      return mk_legal(ap, flags, OP_FLOAT);
    default:
      break;
    }
    break;
  default:
    break;
  }
  FATAL((__FILE__, "g_cast", "illegal combination type1=%d, type2=%d", tp1->type, tp2->type));
  return NIL_ADDRESS;
}

#ifdef ASM
static ADDRESS *g_asm P1(const EXPR *, ep) {
  ADDRESS *ap = mk_expr(am_str, copynode(ep));

  g_code(op_asm, OP_INT, ap, NIL_ADDRESS);
  return NIL_ADDRESS;
}
#endif /* ASM */

/*
 * general expression evaluation. returns the addressing mode of the result.
 */
static ADDRESS *g_expr P2(const EXPR *, ep, FLAGS, flags) {
  ADDRESS *ap1;
  LABEL lab0, lab1;
  ITYPE size;
  TYP *tp = ep->etp;
  OPCODE op;

  if (ep == NIL_EXPR) {
    FATAL((__FILE__, "g_expr", "ep == 0"));
  }
  if (tst_const(ep)) {
    /* check if node contains no label */
    /*
     * F_DIRECT is set if immediate will be converted to direct
     * so we can avoid non necessary doubleindirection
     */
    if ((flags & F_DIRECT) || tst_iconst(ep)) {
      /*
       *  am_immediate is only allowed if:
       *  -Value is short and will not be used as direct (we dont
       *   know content of dp, so directaccess is forbidden) and
       *   will not be used as unsigned immediate
       *
       *  -Value is unsigned short and will not be used as direct
       *   (we dont know content of dp, so directaccess is forbidden)
       *   and will not be used as signed immediate
       *
       *  -Value is a label or an expression containing a label
       *   and will later be used for directacces (it is assumed
       *   that dp points to the page of labels)
       *
       */

      if ((is_short(ep) && ((flags & (F_DIRECT | F_UNSIGNED)) == 0)) ||
          (is_ushort(ep) && ((flags & (F_DIRECT | F_UNSIGNED)) == F_UNSIGNED)) || ((flags & F_DIRECT) && (!tst_iconst(ep)))) {
        ap1 = mk_expr(am_immed, copynode(ep));
      } else {
        if ((flags & F_MEM) && (opt_const_in_ram != OPT_NO)) {
          ap1 = mk_ilabel(copynode(ep));
        } else {
          ap1 = temporary_register(best_flags(flags, F_XREG));
          g_immed(op_ldi, (long)ep->v.i, ap1);
        }
      }
      return mk_legal(ap1, flags, OP_INT);
    } else {
      ap1 = mk_ilabel(ep);
      return mk_legal(ap1, flags, OP_INT);
    }
  }
#ifdef FLOAT_SUPPORT
  size = is_floating_type(tp) ? OP_FLOAT : OP_INT;
#else
  size = OP_INT;
#endif /* FLOAT_SUPPORT */

  switch (ep->nodetype) {
  case en_autocon:
    ap1 = address_register();
    g_immed(op_ldi, (long)ep->v.i, ap1);
    g_code(op_addi, OP_INT, mk_reg(frameptr), ap1);
    return mk_legal(ap1, flags, size);
  case en_register:
    ap1 = mk_reg(ep->v.r & (~FLOAT_REG));
    if ((ep->v.r & FLOAT_REG) != 0) {
      ap1->mode = am_freg;
    }
    return mk_legal(ap1, flags, size);
  case en_ref:
    /*
     * g_deref uses flags and size only to test F_USES
     *
     * If the result is not used, autoincrement addressing
     * modes are wrong!
     */
    if (flags & F_NOVALUE) {
      ap1 = g_deref(ep->v.p[0], tp, (FLAGS)(flags | F_USES));
    } else {
      ap1 = g_deref(ep->v.p[0], tp, flags);
    }
    if (is_structure_type(tp) || is_array_type(tp)) {
      return mk_legal(ap1, flags, OP_INT);
    } else {
      return mk_legal(ap1, flags, size);
    }
  case en_fieldref:
    return g_fderef(ep, flags);
  case en_uminus:
    return g_unary(ep, flags, op_negi);
  case en_compl:
    return g_unary(ep, flags, op_not);
  case en_add:
    return g_addsub(ep, flags, op_addi);
  case en_sub:
    return g_addsub(ep, flags, op_subi);
  case en_and:
    if (ep->v.p[1]->nodetype == en_compl) {
      EXPR *ep1 = (EXPR *)ep;

      ep1->v.p[1] = ep1->v.p[1]->v.p[0];
      return g_logic(ep1, flags, op_andn);
    } else {
      return g_logic(ep, flags, op_and);
    }
  case en_or:
    return g_logic(ep, flags, op_or);
  case en_xor:
    return g_logic(ep, flags, op_xor);
  case en_mul:
    return g_mul(ep, flags);
  case en_div:
    return g_div(ep, flags, FALSE);
  case en_mod:
    return g_div(ep, flags, TRUE);
  case en_lsh:
    return g_shift(ep, flags, (is_unsigned_type(tp) ? op_lsh : op_ash));
  case en_asadd:
    return g_asadd(ep, flags, op_addi);
  case en_assub:
    return g_asadd(ep, flags, op_subi);
  case en_asand:
    if (ep->v.p[1]->nodetype == en_compl) {
      EXPR *ep1 = (EXPR *)ep;

      ep1->v.p[1] = ep1->v.p[1]->v.p[0];
      return g_aslogic(ep1, flags, op_andn);
    } else {
      return g_aslogic(ep, flags, op_and);
    }
  case en_asor:
    return g_aslogic(ep, flags, op_or);
  case en_asxor:
    return g_aslogic(ep, flags, op_xor);
  case en_aslsh:
    return g_asshift(ep, flags, (is_unsigned_type(tp) ? op_lsh : op_ash));
  case en_asmul:
    return g_asmul(ep, flags);
  case en_asdiv:
    return g_asdiv(ep, flags, FALSE);
  case en_asmod:
    return g_asdiv(ep, flags, TRUE);
  case en_assign:
    return g_assign(ep, flags);
  case en_ainc:
    return g_aincdec(ep, flags, op_addi);
  case en_adec:
    return g_aincdec(ep, flags, op_subi);
  case en_eq:
    VOIDCAST g_compare(ep);
    op = op_ldieq;
    goto cont1;
  case en_ne:
    VOIDCAST g_compare(ep);
    op = op_ldine;
    goto cont1;
  case en_lt:
    op = g_compare(ep) ? op_ldilo : op_ldilt;
    goto cont1;
  case en_le:
    op = g_compare(ep) ? op_ldils : op_ldile;
    goto cont1;
  case en_gt:
    op = g_compare(ep) ? op_ldihi : op_ldigt;
    goto cont1;
  case en_ge:
    op = g_compare(ep) ? op_ldihs : op_ldige;
    goto cont1;
  case en_test:
    g_test(ep->v.p[0]);
    op = op_ldine;
    goto cont1;
  case en_not:
    g_test(ep->v.p[0]);
    op = op_ldieq;
  cont1:
    ap1 = temporary_register(best_flags(flags, F_XREG));
    g_code(op_ldiu, OP_INT, mk_immed(0L), ap1);
    g_code(op, OP_INT, mk_immed(1L), ap1);
    return mk_legal(ap1, flags, size);
  case en_land:
  case en_lor:
    lab0 = nextlabel++;
    lab1 = nextlabel++;
    g_falsejp(ep, lab0);
    ap1 = temporary_register(best_flags(flags, F_XREG));
    g_code(op_ldi, OP_INT, mk_immed(1L), ap1);
    g_branch(lab1);
    g_label(lab0);
    g_code(op_ldi, OP_INT, mk_immed(0L), ap1);
    g_label(lab1);
    return mk_legal(ap1, flags, size);
  case en_cond:
    return g_hook(ep, flags);
  case en_comma:
    freeop(g_expr(ep->v.p[0], (FLAGS)(F_ALL | F_NOVALUE)));
    return g_expr(ep->v.p[1], flags);
  case en_fcall:
    return g_fcall(ep, flags);
  case en_cast:
    /*
     * On the TMS320C30, do only casts when changing from
     * floatingpoint to integertypes or vica versa
     */
    switch (ep->etp->type) {
    case bt_float:
    case bt_double:
    case bt_longdouble:
      switch (ep->v.p[0]->etp->type) {
      case bt_float:
      case bt_double:
      case bt_longdouble:
        return g_expr(ep->v.p[0], flags);
      default:
        /*
         * The cast really results in some work
         */
        return g_cast(g_expr(ep->v.p[0], (FLAGS)(F_IALL | F_USES)), ep->v.p[0]->etp, ep->etp, flags);
      }
      break;
    default:
      switch (ep->v.p[0]->etp->type) {
      case bt_float:
      case bt_double:
      case bt_longdouble:
        /*
         * The cast really results in some work
         */
        return g_cast(g_expr(ep->v.p[0], (FLAGS)(F_FALL | F_USES)), ep->v.p[0]->etp, ep->etp, flags);
      default:
        return g_expr(ep->v.p[0], flags);
      }
      break;
    }
    CANNOT_REACH_HERE();

  case en_deref:
    /*
     * The cases where this node occurs are handled automatically:
     * g_assign and g_fcall return a pointer to a structure rather than a
     * structure.
     */
    return g_expr(ep->v.p[0], flags);
#ifdef ASM
  case en_str:
    return g_asm(ep);
#endif /* ASM */

  case en_fcon:
    ap1 = mk_expr(am_immed, copynode(ep));
    return mk_legal(ap1, flags, OP_FLOAT);
  default:
    FATAL((__FILE__, "g_expr", "uncoded node %d", ep->nodetype));
    return NIL_ADDRESS;
  }
}

PRIVATE void g_expression P1(const EXPR *, ep) {
  initstack();
  if (ep != NIL_EXPR) {
    VOIDCAST g_expr(ep, (FLAGS)(F_ALL | F_NOVALUE));
  }
  checkstack();
}

/*
 * generate code to do a comparison of the two operands of node. returns 1 if
 * it was an unsigned comparison
 */
static BOOL g_compare P1(const EXPR *, ep) {
  ADDRESS *ap1, *ap2;
  TYP *tp = ep->v.p[0]->etp;

  switch (tp->type) {
  case bt_uchar:
  case bt_schar:
  case bt_char:
  case bt_charu:
  case bt_ushort:
  case bt_short:
  case bt_int16:
  case bt_uint16:
  case bt_int32:
  case bt_uint32:
  case bt_long:
  case bt_ulong:
  case bt_pointer32:
    ap2 = g_expr(ep->v.p[1], F_IALL);
    ap1 = g_expr(ep->v.p[0], F_XREG);
    validate(ap2);
    /* sinc cmpi only reads 2 operands we use g_code3 and   */
    /* don't use dst ap, even if cmpi is in fact a 2-operand instr. */
    /* makes the job for the peephole-optimizer easier */
    g_code3(op_cmpi, OP_INT, ap2, ap1, NIL_ADDRESS);
    freeop(ap1);
    freeop(ap2);
    return is_unsigned_type(tp);

  case bt_float:
  case bt_double:
  case bt_longdouble:
    ap2 = g_expr(ep->v.p[1], F_FALL);
    ap1 = g_expr(ep->v.p[0], F_FREG);
    validate(ap2);
    /* sinc cmpf only reads 2 operands we use g_code3 and   */
    /* don't use dst ap, even if tszb is in fact a 2-operand instr. */
    /* makes the job for the peephole-optimizer easier */
    g_code3(op_cmpf, OP_FLOAT, ap2, ap1, NIL_ADDRESS);
    freeop(ap1);
    freeop(ap2);
    return FALSE;
  default:
    break;
  }
  FATAL((__FILE__, "g_compare", "illegal type %d", ep->v.p[0]->etp->type));
  return FALSE;
}

/*
 * Test the expression and set the condition codes accordingly
 */
static void g_test P1(const EXPR *, ep) {
  ADDRESS *ap;

  switch (ep->etp->type) {
#ifdef FLOAT_SUPPORT
  case bt_float:
  case bt_double:
  case bt_longdouble:
    ap = g_expr(ep, F_FREG);
    /* sinc cmpf only reads 2 operands we use g_code3 and   */
    /* don't use dst ap, even if tszb is in fact a 2-operand instr. */
    /* makes the job for the peephole-optimizer easier */

    g_code3(op_cmpf, OP_FLOAT, mk_immedfloat(0.0), ap, NIL_ADDRESS);
    freeop(ap);
    /* note that the condition codes are tested,
       not the return value */
    break;
#endif /* FLOAT_SUPPORT */
  default:
    ap = g_expr(ep, (FLAGS)(F_IALL & ~F_IMMED));
    /* tstb allows only [reg | ind | indx2] <-> [reg | ind | indx2] */
    if ((ap->mode == am_direct) || (ap->mode == am_const_direct) || (ap->mode == am_indx)) {
      ap = mk_legal(ap, F_XREG, OP_INT);
    }
    if ((ap->mode == am_ind) || (ap->mode == am_const_ind) || (ap->mode == am_indx2) || (ap->mode == am_indxs)) {
      g_code3(op_tstb3, OP_INT, ap, ap, NIL_ADDRESS);
    } else {
      /* sinc testb only reads 2 operands we use g_code3 and   */
      /* don't use dst ap, even if tszb is in fact a 2-operand instr. */
      /* makes the job for the peephole-optimizer easier */

      g_code3(op_tstb, OP_INT, ap, ap, NIL_ADDRESS);
    }
    freeop(ap);
  }
}

/*
 * generate a jump to label if the node passed evaluates to a true condition.
 */
static void g_truejp P2(const EXPR *, ep, LABEL, label) {
  LABEL lab0;
  OPCODE op;

  if (ep == NIL_EXPR)
    FATAL((__FILE__, "g_truejp", "ep == 0"));
  switch (ep->nodetype) {
  case en_icon:
    if (ep->v.i) {
      g_branch(label);
    }
    break;
  case en_eq:
    VOIDCAST g_compare(ep);
    op = op_beq;
    g_cbranch(op, label);
    break;
  case en_ne:
    VOIDCAST g_compare(ep);
    op = op_bne;
    g_cbranch(op, label);
    break;
  case en_lt:
    op = g_compare(ep) ? op_blo : op_blt;
    g_cbranch(op, label);
    break;
  case en_le:
    op = g_compare(ep) ? op_bls : op_ble;
    g_cbranch(op, label);
    break;
  case en_gt:
    op = g_compare(ep) ? op_bhi : op_bgt;
    g_cbranch(op, label);
    break;
  case en_ge:
    op = g_compare(ep) ? op_bhs : op_bge;
    g_cbranch(op, label);
    break;
  case en_land:
    lab0 = nextlabel++;
    g_falsejp(ep->v.p[0], lab0);
    g_truejp(ep->v.p[1], label);
    g_label(lab0);
    break;
  case en_lor:
    g_truejp(ep->v.p[0], label);
    g_truejp(ep->v.p[1], label);
    break;
  case en_not:
    /*g_test(ep->v.p[0]);
     *g_cbranch(op_beq, label);
     */
    g_falsejp(ep->v.p[0], label);
    break;
  case en_test:
    g_test(ep->v.p[0]);
    g_cbranch(op_bne, label);
    break;
  case en_call: /* library routine which sets the flags */
    freeop(g_expr(NIL_EXPR, (FLAGS)-1) /*ep, F_ALL) */);
    g_cbranch(op_bne, label);
    break;
  default:
    /* only happens when called from g_falsejp in case en_not */
    g_test(ep);
    g_cbranch(op_bne, label);
    break;
  }
}

/*
 * generate code to execute a jump to label if the expression passed is
 * false.
 */
static void g_falsejp P2(const EXPR *, ep, LABEL, label) {
  LABEL lab0;
  OPCODE op;

  if (ep == NIL_EXPR) {
    FATAL((__FILE__, "g_falsejp", "ep == 0"));
  }
  switch (ep->nodetype) {
  case en_icon:
    if (!ep->v.i) {
      g_branch(label);
    }
    break;
  case en_eq:
    VOIDCAST g_compare(ep);
    op = op_bne;
    g_cbranch(op, label);
    break;
  case en_ne:
    VOIDCAST g_compare(ep);
    op = op_beq;
    g_cbranch(op, label);
    break;
  case en_lt:
    op = g_compare(ep) ? op_bhs : op_bge;
    g_cbranch(op, label);
    break;
  case en_le:
    op = g_compare(ep) ? op_bhi : op_bgt;
    g_cbranch(op, label);
    break;
  case en_gt:
    op = g_compare(ep) ? op_bls : op_ble;
    g_cbranch(op, label);
    break;
  case en_ge:
    op = g_compare(ep) ? op_blo : op_blt;
    g_cbranch(op, label);
    break;
  case en_land:
    g_falsejp(ep->v.p[0], label);
    g_falsejp(ep->v.p[1], label);
    break;
  case en_lor:
    lab0 = nextlabel++;
    g_truejp(ep->v.p[0], lab0);
    g_falsejp(ep->v.p[1], label);
    g_label(lab0);
    break;
  case en_not:
    /*g_test(ep->v.p[0]);
     *g_cbranch(op_bne, label);
     */
    g_truejp(ep->v.p[0], label);
    break;
  case en_test:
    g_test(ep->v.p[0]);
    g_cbranch(op_beq, label);
    break;
  case en_call: /* library routine which sets the flags */
    freeop(g_expr(NIL_EXPR, (FLAGS)-1 /*ep, F_ALL */));
    g_cbranch(op_beq, label);
    break;
  default:
    /* only happens when called from g_falsejp in case en_not */
    g_test(ep);
    g_cbranch(op_beq, label);
    break;
  }
}

/*
 * generate a conditional load.
 */
PRIVATE ADDRESS *g_conditionalload P5(const EXPR *, ep, ADDRESS *, truesrc, ADDRESS *, falsesrc, ITYPE, type, FLAGS, flags) {
  OPCODE op, op2;
  ADDRESS *ap1;

  if (ep == NIL_EXPR)
    FATAL((__FILE__, "g_conditionalload", "ep == 0"));
  switch (ep->nodetype) {
  case en_icon:
    op = (type == OP_INT) ? op_ldi : op_ldf;
    ap1 = (type == OP_INT) ? temporary_register(best_flags(flags, F_XREG)) : data_register(F_FREG);
    freeop(truesrc);
    freeop(falsesrc);
    if (ep->v.i) {
      g_code(op, type, truesrc, ap1);
    } else {
      g_code(op, type, falsesrc, ap1);
    }
    break;

  case en_eq:
    VOIDCAST g_compare(ep);
    op = (type == OP_INT) ? op_ldieq : op_ldfeq;
    op2 = (type == OP_INT) ? op_ldine : op_ldfne;
    goto common;

  case en_ne:
    VOIDCAST g_compare(ep);
    op = (type == OP_INT) ? op_ldine : op_ldfne;
    op2 = (type == OP_INT) ? op_ldieq : op_ldfeq;
    goto common;

  case en_lt:
    if (g_compare(ep)) {
      op = (type == OP_INT) ? op_ldilo : op_ldflo;
      op2 = (type == OP_INT) ? op_ldihs : op_ldfhs;
    } else {
      op = (type == OP_INT) ? op_ldilt : op_ldflt;
      op2 = (type == OP_INT) ? op_ldige : op_ldfge;
    }
    goto common;

  case en_le:
    if (g_compare(ep)) {
      op = (type == OP_INT) ? op_ldils : op_ldfls;
      op2 = (type == OP_INT) ? op_ldihi : op_ldfhi;
    } else {
      op = (type == OP_INT) ? op_ldile : op_ldfle;
      op2 = (type == OP_INT) ? op_ldigt : op_ldfgt;
    }
    goto common;

  case en_gt:
    if (g_compare(ep)) {
      op = (type == OP_INT) ? op_ldihi : op_ldfhi;
      op2 = (type == OP_INT) ? op_ldils : op_ldfls;
    } else {
      op = (type == OP_INT) ? op_ldigt : op_ldfgt;
      op2 = (type == OP_INT) ? op_ldile : op_ldfle;
    }
    goto common;

  case en_ge:
    if (g_compare(ep)) {
      op = (type == OP_INT) ? op_ldihs : op_ldfhs;
      op2 = (type == OP_INT) ? op_ldilo : op_ldflo;
    } else {
      op = (type == OP_INT) ? op_ldige : op_ldfge;
      op2 = (type == OP_INT) ? op_ldilt : op_ldflt;
    }
    goto common;

  case en_test:
    g_test(ep->v.p[0]);
    op = (type == OP_INT) ? op_ldieq : op_ldfeq;
    op2 = (type == OP_INT) ? op_ldine : op_ldfne;

  common:
    validate(truesrc);
    validate(falsesrc);
    freeop(truesrc);
    freeop(falsesrc);
    ap1 = (type == OP_INT) ? temporary_register(best_flags(flags, F_XREG)) : data_register(F_FREG);
    if (falsesrc->mode == am_immed) {
      g_code((type == OP_INT) ? op_ldiu : op_ldfu, type, truesrc, ap1);
      g_code(op2, type, falsesrc, ap1);
    } else {
      g_code((type == OP_INT) ? op_ldiu : op_ldfu, type, falsesrc, ap1);
      g_code(op, type, truesrc, ap1);
    }
    break;

  case en_land:
  case en_lor:
    FATAL((__FILE__, "g_conditionalload", "en_land/en_lor"));
    break;
  case en_not:
    ap1 = g_conditionalload(ep->v.p[1], falsesrc, truesrc, type, flags);
    break;
  default:
    FATAL((__FILE__, "g_conditionalload", "ilegal nodetype"));
    CANNOT_REACH_HERE();
    /*g_test (ep);
       validate (truesrc);
       validate (falsesrc);
       freeop (truesrc);
       freeop (falsesrc);
       ap1 = (type == OP_INT) ? temporary_register (F_XREG) : data_register (F_FREG);
       op = (type == OP_INT) ? op_ldieq : op_ldfeq;
       op2 = (type == OP_INT) ? op_ldine : op_ldfne;
       if (falsesrc->mode == am_immed) {
       g_code ((type == OP_INT) ? op_ldiu : op_ldfu, type, truesrc, ap1);
       g_code (op2, type, falsesrc, ap1);
       } else {
       g_code ((type == OP_INT) ? op_ldiu : op_ldfu, type, falsesrc, ap1);
       g_code (op, type, truesrc, ap1);
       }
       break; */
  }
  return (ap1);
}

PRIVATE void g_jtrue P2(const EXPR *, ep, LABEL, label) {
  initstack();
  g_truejp(ep, label);
  checkstack();
}

PRIVATE void g_jfalse P2(const EXPR *, ep, LABEL, label) {
  initstack();
  g_falsejp(ep, label);
  checkstack();
}

PRIVATE void g_switch_table P4(const EXPR *, ep, struct swtab *, sw, UVAL, min_caselabel, UVAL, max_caselabel) {
  ADDRESS *ap, *ap1, *ap2;

  initstack();
  ap = g_expr(ep, (FLAGS)(F_XREG | F_VOL));
  /*
   * move the interval
   */
  if (min_caselabel != (UVAL)0) {
    g_immed(op_subi, (IVAL)min_caselabel, ap);
  }
  /* sinc cmpi only reads 2 operands we use g_code3 and   */
  /* don't use dst ap, even if tszb is in fact a 2-operand instr. */
  /* makes the job for the peephole-optimizer easier */
  g_code3(op_cmpi, OP_INT, mk_immed(max_caselabel - min_caselabel), ap, NIL_ADDRESS);
  g_cbranch(op_bhi, sw->deflab);
  ap1 = address_register();
  g_code(op_ldi, OP_INT, mk_ilabel(mk_lcon(sw->tablab)), ap1);
  /* jump table contains 4 byte address of case branches */
  g_code(op_addi, OP_INT, ap, ap1);
  freeop(ap1);
  freeop(ap);
  ap1 = copy_addr(ap1, am_const_ind);
  ap2 = temporary_register(F_XREG);
  g_code(op_ldi, OP_INT, ap1, ap2);

  /* to have a connection between jumptable and switchjump */
  /* sinc ap2 is am_areg, this 'extra-offset' will be ignored */
  /* by the rest of the compiler */
  ap2->u.offset = mk_lcon(sw->tablab);

  g_code(op_bu, OP_INT, ap2, NIL_ADDRESS);
  freeop(ap2);
  checkstack();
}

/*
 * Generate the body of a switch statement by comparing each case value
 * in turn.   The comparision is infact done by using subtraction as this
 * actually generates more efficient code (and would work best if the
 * labels were sorted!)
 */
#if 0
PRIVATE void g_switch_compare P2 (const EXPR *, ep, STMT *, stmt)
{
    IVAL    min_value;
    ADDRESS *ap;

    initstack ();
    ap = g_expr (ep, (FLAGS) (F_XREG | F_VOL));
    for (min_value = 0; stmt != NIL_STMT; stmt = stmt->s1) {
	if (stmt->stype != st_default) {
	    g_immed (op_subi, (long) (stmt->v2.i - min_value), ap);
	    min_value = stmt->v2.i;
	    stmt->v2.l = nextlabel++;
	    g_cbranch (op_beq, stmt->v2.l);
	}
    }
    freeop (ap);
    checkstack ();
}

#else
/*
 * New variant, finds out if there is a conected valuerange to
 * the same label and uses a cmp-instruction instead of a chain of
 * subi 1, rx
 */
PRIVATE void g_switch_compare P2(const EXPR *, ep, STMT *, stmt) {
  IVAL min, max;
  IVAL min_value = 0L;
  LABEL label;
  ADDRESS *ap;

  initstack();
  ap = g_expr(ep, (FLAGS)(F_XREG | F_VOL));
  while (stmt != NIL_STMT) {
    if (stmt->stype != st_default) {
      for (min = stmt->v2.i; stmt != NIL_STMT; stmt = stmt->s1) {
        max = stmt->v2.i;
        stmt->v2.l = label = nextlabel++;
        if ((stmt->s1 == NIL_STMT) || (stmt->s1->stype == st_default) || (stmt->s1 != stmt->v1.s) ||
            (stmt->s1->v2.i != max + 1l)) {
          stmt = stmt->s1;
          break;
        }
      }
      if ((min - min_value) < 0L) {
        g_immed(op_addi, min_value - min, ap);
      } else {
        g_immed(op_subi, min - min_value, ap);
      }
      min_value = min;
      switch (max - min) {
      case 1:
        g_cbranch(op_beq, label);
        g_immed(op_subi, 1L, ap);
        min_value++;
        /*FALLTHRU */
      case 0:
        g_cbranch(op_beq, label);
        break;
      default:
        g_immed(op_cmpi, max - min_value, ap);
        g_cbranch(op_bls, label);
        break;
      }
    } else {
      stmt = stmt->s1;
    }
  }
  freeop(ap);
  checkstack();
}
#endif
/*
 *   Generate the code for setting up any local variables and
 *   the saving of any registers used.    This code is actually
 *   generated at the end of the function when the amount of
 *   stackspace actually required is known .... the peephole
 *   optimiser will move it back to the start of the function.
 */
PRIVATE void g_entry P1(SIZE, frame_size) {
#ifdef STACK_CHECK
  if ((stackcheck_option) && (interrupt_option == OPT_NO)) {
    SYM *sp = internal_symbol(SUP_STACKCHECK, NIL_TYP);

    /*
     * trashes a temporary dataregister, but this is no
     * problem, since stackcheck is not allowed in
     * interruptroutines and otherwise temporarys must not
     * be saved
     */

    ADDRESS *ap1 = data_register(F_DREG);

    g_immed(op_ldi, frame_size + max_stack_adjust, ap1);
    g_code(op_push, OP_INT, ap1, NIL_ADDRESS);
    g_code(op_call, OP_INT, mk_strlab(sp->name), NIL_ADDRESS);
  }
#endif /* STACK_CHECK */
  if (frame_size < 32768L) {
    g_code(op_push, OP_INT, mk_reg(frameptr), NIL_ADDRESS);
    g_code(op_ldi, OP_INT, mk_reg(STACKPTR), mk_reg(frameptr));
    if (frame_size != 0L) {
      /*
       * addi is also allowed in interruptroutines since
       * addi n,sp does not change statusregister
       * (and SR is saved after the addi-instr.)
       */
      g_immed(op_addi, frame_size, mk_reg(STACKPTR));
    }
  } else {
    FATAL((__FILE__, "g_entry", "framesize > 32768"));
  }

  /* Save used registers onto stack */
  if (restore_mask != (REGMASK)0) {
    push_registers(restore_mask, floatrestore_mask);
  }
  max_stack_adjust = 0L;
}

/*
 *   Generate the code for a "return" statement.  This ensures
 *   that any returned result is loaded into the appropriate
 *   register.
 */
PRIVATE void g_return P2(const EXPR *, stmtexp, TYP *, tp) {
  EXPR *ep, *ep1;
  ADDRESS *ap;

  return_register_mask = 1L << RESULT;
  initstack();
  switch (tp->type) {
  case bt_struct:
  case bt_union:
    /* assign structure */
    ep = mk_autocon((SIZE)-2L);
    ep = mk_ref(ep, tp_pointer);
    ep1 = mk_ref(ep, tp);
    ep1 = mk_node(en_assign, ep1, copynode(stmtexp), tp);
    VOIDCAST g_expr(ep1, (FLAGS)(F_ALL | F_NOVALUE));

    ap = g_expr(ep, F_IALL);
    g_code(op_ldi, OP_INT, ap, mk_reg(RESULT));
    freeop(ap);
    break;

  case bt_longdouble:
  case bt_double:
  case bt_float:
    ap = g_expr(stmtexp, F_FALL);
    g_code(op_ldf, OP_FLOAT, ap, mk_freg(RESULT));
    freeop(ap);
    break;

  case bt_char:
  case bt_charu:
  case bt_uchar:
  case bt_schar:
  case bt_short:
  case bt_ushort:
  case bt_int16:
  case bt_uint16:
  case bt_int32:
  case bt_uint32:
  case bt_long:
  case bt_ulong:
  case bt_pointer32:
    ap = g_expr(stmtexp, F_IALL);
    g_code(op_ldi, OP_INT, ap, mk_reg(RESULT));
    freeop(ap);
    break;
  default:
    FATAL((__FILE__, "g_return", "illegal type %d", tp->type));
  }
}

/*
 *   Generate the code required at the end of a function to
 *   restore any used registers and the return instruction itself.
 */
PRIVATE void g_epilogue P0(void) {
  ADDRESS *ap;
  SIZE stackoffset;

  /*
   * Check if more registers are to be saved than used by the function
   * due to options set by user
   */

  if ((interrupt_option != OPT_NO) || ((forced_save_mask | forced_floatsave_mask) != 0)) {
    REG r;

    /* Mask out unwanted registers */
    /* which should not be pushed by force (SP, ST and IF) */
    forced_save_mask &= ~((1L << REG_ST) | (1L << REG_SP) | (1L << REG_IF) | (1L << REG_IE) | (1L << REG_IOF));
    /* If we are forced be an option to save more registers */
    restore_mask |= forced_save_mask;
    floatrestore_mask |= forced_floatsave_mask;

    if (interrupt_option != OPT_NO) {
      if (is_leaf_function) {

        /* Save only those temporaryregisters additionally wich are really used */
        interrupt_restore_mask &= ALL_TEMPORARYS | (1L << REG_RC) | (1L << REG_RS) | (1L << REG_RE);

        interrupt_restore_mask |= 1L << REG_ST;
        restore_mask |= interrupt_restore_mask;

        interrupt_floatrestore_mask &= ((1L << REG_R0) | (1L << REG_R1) | (1L << REG_R2));

        floatrestore_mask |= interrupt_floatrestore_mask;

      } else {
        /*
         * Save at least all temporarys since this is not a leaf function
         * and we have no way to tell which rgisters are used by the called functions
         */
        restore_mask |= ALL_TEMPORARYS | (1L << REG_ST) | (1L << REG_RC) | (1L << REG_RS) | (1L << REG_RE);

        floatrestore_mask |= (1L << REG_R0) | (1L << REG_R1) | (1L << REG_R2);
      }
    }
    /* Mask out registers we really do not want to save */
    restore_mask &= ~(1UL << frameptr);
    restore_mask &= ~return_register_mask;
    floatrestore_mask &= ~return_register_mask;

    /* count the saved registers (to calculate space on stack) */
    regs_used = 0;
    address_reg_used = 0;

    for (r = REG_R0; r <= MAX_REG; r++) {
      if (((1L << r) & (restore_mask)) != 0) {
        regs_used++;
        if (is_address_register(r)) {
          address_reg_used++;
        }
      }
    }
    for (r = REG_R0; r <= REG_R7; r++) {
      if (((1L << r) & (floatrestore_mask)) != 0) {
        regs_used++;
      }
    }
  }
  /* Clean up for the next function (reinit) */
  interrupt_restore_mask = 0;
  interrupt_floatrestore_mask = 0;
  return_register_mask = 0;

  if (regs_used > 0) {
    if (is_leaf_function) {
      pop_registers(restore_mask, floatrestore_mask);
    } else {
      if (lc_auto > lc_auto_max) {
        lc_auto_max = lc_auto;
      }
      stackoffset = lc_auto_max + max_scratch + regs_used;
      if ((stackoffset > 255) || (address_reg_used > 2)) {
        ap = mk_reg(REG_AR0);
        g_immed(op_ldi, stackoffset, ap);
        g_code3(op_addi3, OP_INT, mk_reg(frameptr), ap, mk_reg(STACKPTR));
        pop_registers(restore_mask, floatrestore_mask);
      } else {
        pop_fast_registers(restore_mask, floatrestore_mask, stackoffset);
      }
    }
  }
  g_code(op_ldi, OP_INT, mk_reg(frameptr), mk_reg(STACKPTR));
  g_code(op_pop, OP_INT, NIL_ADDRESS, mk_reg(frameptr));
  if (interrupt_option == OPT_NO) {
    g_code(op_retsu, OP_INT, NIL_ADDRESS, NIL_ADDRESS);
  } else {
    g_code(op_retiu, OP_INT, NIL_ADDRESS, NIL_ADDRESS);
  }
}

/*
 * allocate will allocate registers for the expressions that have a high
 * enough desirability.
 */
PRIVATE void g_allocate P1(CSE *, olist) {
  CSE *csp;
  REG datareg = REG_R7;
  REG addreg = (REG)((int)frameptr - 1);
  REGMASK mask = (REGMASK)0;
  REGMASK floatmask = (REGMASK)0;

  regs_used = 0;
  address_reg_used = 0;
  for (csp = olist; csp != NIL_CSE; csp = csp->next) {
    /*
     * If reg_option is not true, the 'desire' value must be at least
     * 5000, which I hope can only be achieved by the 'register' attribute
     */
    if (desire(csp) < 3 || (!reg_option && desire(csp) < 5000) || (is_function_type(csp->exp->etp))) {
      csp->reg = NO_REG;
      /*
       * code gets more inefficient when enabling following statements
       * was thought to supress loading the address of a static or global
       * into an addressregister and use the addressregister instead directaddressing
       * but use of addressregs allows 3-operand-instructions and leads thus
       * to much better code.
       *       } else if (  (opt_peep_test > 5)&&(opt_peep_test < 15)
       *                 &&(  (csp->exp->nodetype == en_labcon)
       *                    ||(csp->exp->nodetype == en_nacon))) {
       *          csp->reg = NO_REG;
       */
    } else if (csp->duses > (csp->uses / (unsigned)3) &&
               !is_temporary_register(addreg)
               /*
                * integer constants may have different types
                */
               && csp->exp->nodetype != en_icon
               /*
                * the types which are fine in address registers
                * allow only 32-bit integral and signed 16-bit integral types
                */
               && (csp->exp->etp->type == bt_short || csp->exp->etp->type == bt_int16 || csp->exp->etp->type == bt_int32 ||
                   csp->exp->etp->type == bt_uint32 || csp->exp->etp->type == bt_long || csp->exp->etp->type == bt_ulong ||
                   csp->exp->etp->type == bt_pointer32)) {
      csp->reg = addreg--;
      address_reg_used++;
    } else if (!is_temporary_register(datareg) && !is_short(csp->exp) && (csp->exp->etp->type != bt_pointer32)) {

      /*
       * the types which are fine in data registers:
       * allow all types except pointers
       */
      /* Floatnumber need some special handling */
      if (csp->exp->etp->type == bt_float || csp->exp->etp->type == bt_double || csp->exp->etp->type == bt_longdouble) {
        /*  numbers with bit FLOAT_REG set indicate floatingregisters */
        floatmask |= (1L << datareg);
        csp->reg = FLOAT_REG | datareg--;
        /* regs used must be incremented twice for float    */
        /* sinc pushed floatregisters need 2 words on stack */
        regs_used++;
      } else {
        csp->reg = datareg--;
      }
    } else {
      csp->reg = NO_REG;
    }
    if (csp->reg != NO_REG) {
      regs_used++;
      mask |= (1L << ((~FLOAT_REG) & (csp->reg)));
    }
  }
  if (!is_temporary_register(addreg)) {
    /* maybe we can allocate some of the address registers */
    for (csp = olist; csp != NIL_CSE && !is_temporary_register(addreg); csp = csp->next) {
      if (csp->reg != NO_REG || /* already allocated to a register */
          desire(csp) < 3 ||    /* not desirable in a register */
          (!reg_option && desire(csp) < 5000) || (is_function_type(csp->exp->etp))) {
        continue;
      }
      /*
       * code gets more inefficient when enabling following statements
       * was thought to supress loading the address of a static or global
       * into an addressregister and use the addressregister instead directaddressing
       * but use of addressregs allows 3-operand-instructions and leads thus
       * to much better code.
       *          if (  (opt_peep_test > 5)&&(opt_peep_test < 15)
       *              &&(  (csp->exp->nodetype == en_labcon)
       *                 ||(csp->exp->nodetype == en_nacon))) {
       *              continue;
       *          }
       */
      if ((csp->exp->nodetype != en_icon) &&
          (csp->exp->etp->type == bt_short || csp->exp->etp->type == bt_int16 || csp->exp->etp->type == bt_int32 ||
           csp->exp->etp->type == bt_uint32 || csp->exp->etp->type == bt_long || csp->exp->etp->type == bt_ulong ||
           csp->exp->etp->type == bt_pointer32)) {
        csp->reg = addreg--;
        address_reg_used++;
        regs_used++;
        mask |= (1L << csp->reg);
      }
    }
  }
  /*
   * is moved now to g_entry
   *   if (mask != 0) {
   *       push_registers(mask, floatmask);
   *   }
   */
  restore_mask = mask;
  floatrestore_mask = floatmask;
}

PRIVATE void g_preload P1(CSE *, olist) {
  CSE *csp;
  EXPR *ep;
  ADDRESS *ap, *ap2;

  for (csp = olist; csp != NIL_CSE; csp = csp->next) {
    if (csp->reg != NO_REG) { /* see if preload needed */
      ep = csp->exp;
      if (!is_lvalue(ep) || (ep->v.p[0]->v.i < 0L)) {
        initstack();
        if ((csp->reg & FLOAT_REG) != 0) {
          ap = g_expr(ep, F_FALL);
          ap2 = mk_freg((REG)((~FLOAT_REG) & (csp->reg)));
          g_code(op_ldf, OP_FLOAT, ap, ap2);
        } else {
          ap = g_expr(ep, F_IALL);
          ap2 = mk_reg(csp->reg);
          g_code(op_ldi, OP_INT, ap, ap2);
        }
        freeop(ap);
      }
    }
  }
}

PRIVATE void g_flush P1(SYM *, sp) {
  put_literals();
  if (sp) {
    put_cseg(alignment_of_type(typeof(sp)));
    put_name(sp);
  }
  flush_peep(peep_option);
}

PRIVATE void g_auto_align P0(void) {
  SIZE default_alignment = AL_DEFAULT;

  if (lc_auto_max % default_alignment != 0L) {
    lc_auto_max += default_alignment - (lc_auto_max % default_alignment);
  }
}

PRIVATE BOOL g_is_bigendian P0(void) {
  /* We set it to false to avoid 'bitfield optimisation' in optimice.c */
  /* (it tries to move referencepointer bytewise to save shifts        */
  /* -> TMS cant move pointers bytewise, so let it be                  */
  return FALSE;
}

/*
 *  Defines if the systemstack is growing from low to high addresses (TRUE)
 *  or if it is going down from high to low addresses (more usual) (FALSE)
 *
 */

PRIVATE BOOL g_is_ascending_stack P0(void) { return TRUE; }

/*
 *      This routine does any code generator specific transformations
 *      on the expression tree.
 *
 *      For example it can replace operator nodes with calls to runtime
 *      routines.   This allows the global optimiser to perform optimisations
 *      on such calls which wouldn't be possible if the calls were
 *      generated in the code generator routines themselves.
 */

PRIVATE EXPR *g_transform P1(EXPR *, ep) {
  if (ep == NIL_EXPR)
    return ep;
  switch (ep->nodetype) {
#ifdef FLOAT_SUPPORT
    TYP *tp;

  case en_fcon:
    tp = ep->etp;
    if (!is_short_float(ep->v.f, tp->type)) {
      ep = mk_lcon(mk_flabel(&(ep->v.f), tp));
      ep = mk_ref(ep, tp);
    }
    return ep;
#endif /* FLOAT_SUPPORT */
  case en_icon:
  case en_nacon:
  case en_labcon:
    break;
  case en_autocon:
#if 1
    /* Just for test purposes, should be deleted */
    VOIDCAST printf("astonishing, an autocon here ?\n");
    /*FALLTHRU */
#endif
  case en_sym:
  case en_register:
  case en_size:
    break;
  case en_eq:
  case en_ne:
  case en_lt:
  case en_le:
  case en_gt:
  case en_ge:
  case en_add:
  case en_sub:
  case en_and:
  case en_or:
  case en_xor:
  case en_land:
  case en_lor:
  case en_cond:
  case en_comma:
  case en_list:
  case en_asadd:
  case en_assub:
  case en_asor:
  case en_asxor:
  case en_asand:
  case en_fcall:
  case en_call:
  case en_assign:
  case en_ainc:
  case en_adec:
  case en_aslsh:
  case en_asmul:
  case en_asdiv:
  case en_asmod:
  case en_mul:
  case en_div:
  case en_mod:
  case en_lsh:
    ep->v.p[1] = g_transform(ep->v.p[1]);
    /*FALLTHRU */
  case en_uminus:
  case en_test:
  case en_not:
  case en_compl:
  case en_deref:
  case en_fieldref:
    ep->v.p[0] = g_transform(ep->v.p[0]);
    break;
  case en_ref:

    /*
     * is a quick and dirty try to avoid compilcated
     * dereferencing of autocons due subexpressionoptimizing
     *
     * void dummy(int a, int b)
     * {
     *    *((&a)+32) = b; * repeated multiple times *
     * }
     * then &a gets the common subexpression and is
     * allocated to a register, leading to something like
     * reg = fp+offset;
     *
     * and in later use to
     *
     * *(reg+32) = b
     *
     * but it would be better to put it
     *
     * *(fp+offset+32) = b,
     *
     * this is cheaper, faster and saves an register
     * (works of course only if offset+register is in range
     *  of indexed adressingmode)
     */
#if 0
	if (ep->v.p[0]->nodetype == en_add) {
	    if (is_icon (ep->v.p[0]->v.p[1])
		&& (ep->v.p[0]->v.p[0]->nodetype == en_sym)
		&& ((storageof (ep->v.p[0]->v.p[0]->v.sp) == sc_auto)
		    || (storageof (ep->v.p[0]->v.p[0]->v.sp) == sc_parms))) {
		int     i = ep->v.p[0]->v.p[1]->v.i + ep->v.p[0]->v.p[0]->v.sp->value.i;

		if ((i < 255) && (i > -255)) {
		    SYM    *sp = mk_sym ("CompilerGeneratedC30", sc_parms, typeof (ep->v.p[0]->v.p[0]->v.sp));

		    sp->value.i = i;
		    ep->v.p[0] = mk_node (en_sym, NIL_EXPR, NIL_EXPR, ep->v.p[0]->etp);
		    ep->v.p[0]->v.sp = sp;
		    break;
		}
	    }
	}
#endif
    ep->v.p[0] = g_transform(ep->v.p[0]);
    break;

  case en_cast:

    /* do only cast conversions between integers and floats
     */
    switch (ep->etp->type) {
    case bt_float:
    case bt_double:
    case bt_longdouble:
      switch (ep->v.p[0]->etp->type) {
      case bt_float:
      case bt_double:
      case bt_longdouble:
        return g_transform(ep->v.p[0]);
      default:
        break;
      }
      break;
    default:
      switch (ep->v.p[0]->etp->type) {
      case bt_float:
      case bt_double:
      case bt_longdouble:
        break;
      default:
        return g_transform(ep->v.p[0]);
      }
      break;
    }
    ep->v.p[0] = g_transform(ep->v.p[0]);
    break;

  case en_rsh:
    ep->v.p[0] = g_transform(ep->v.p[0]);
    ep->v.p[1] = g_transform(ep->v.p[1]);
    ep->v.p[1] = mk_node(en_uminus, ep->v.p[1], NIL_EXPR, ep->v.p[1]->etp);
    ep->nodetype = en_lsh;
    return ep;
  case en_asrsh:
    ep->v.p[0] = g_transform(ep->v.p[0]);
    ep->v.p[1] = g_transform(ep->v.p[1]);
    ep->v.p[1] = mk_node(en_uminus, ep->v.p[1], NIL_EXPR, ep->v.p[1]->etp);
    ep->nodetype = en_aslsh;
    return ep;
  default:
    CANNOT_REACH_HERE();
    break;
  }
  return ep;
}

/*
 *      This routine is called after the global optimizer has done it's
 *      work re-organizing the expression tree.  This allows a code
 *      generator to make code generator specific changes to the expression
 *      tree which will result in better code generation.
 */

PRIVATE EXPR *g_order P1(EXPR *, ep) {
  switch (ep->nodetype) {
  case en_and:
    /*
     * Take advantage of the andn instruction
     * (And with the complement of the second operand
     */
    switch (ep->v.p[0]->nodetype) {
    case en_icon:
      if ((ep->v.p[0]->v.i < 0) && (~ep->v.p[0]->v.i < 0xFFFF)) {
        ep->v.p[0]->v.i = ~ep->v.p[0]->v.i;
        ep->v.p[0] = mk_node(en_compl, ep->v.p[0], NIL_EXPR, ep->v.p[0]->etp);
        swap_nodes(ep);
        return (ep);
      }
      break;
    case en_compl:
      if (!is_icon(ep->v.p[1])) {
        swap_nodes(ep);
        return (ep);
      }
    default:
      break;
    }
    /* FALLTHRU */

  case en_asand:
    /*
     * Take advantage of the andn instruction
     * (And with the complement of the second operand
     */
    switch (ep->v.p[1]->nodetype) {
    case en_icon:
      if ((ep->v.p[1]->v.i < 0) && (~ep->v.p[1]->v.i < 0xFFFF)) {
        ep->v.p[1]->v.i = ~ep->v.p[1]->v.i;
        ep->v.p[1] = mk_node(en_compl, ep->v.p[1], NIL_EXPR, ep->v.p[1]->etp);
      }
      break;
    default:
      break;
    }
    break;

  case en_lt:
  case en_gt:
  case en_le:
  case en_ge:
  case en_eq:
  case en_ne:
    switch (ep->v.p[0]->nodetype) {
    case en_register:
      break;
    case en_icon:
      if (is_short(ep->v.p[0]))
        swap_nodes(ep);
      break;
    default:
      switch (ep->v.p[1]->nodetype) {
      case en_register:
        swap_nodes(ep);
        break;
      case en_icon:
        if (!is_short(ep->v.p[1]))
          /* will be in an register if not short, so do swapp */
          swap_nodes(ep);
        break;
      default:
        break;
      }
      break;
    }
    /*FALLTHRU */
  default:
    break;
  }
  return ep;
}

PRIVATE void g_initialize P0(void) {
  tp_pointer->size = tp_string->size = tp_wstring->size = tp_func->size = tp_short->size = tp_ushort->size = tp_int->size =
      tp_uint->size = tp_long->size = tp_ulong->size = tp_float->size = tp_double->size = tp_longdouble->size = tp_size->size =
          tp_ptrdiff->size = tp_wchar->size = 1L;
  bits_in_sizeunit = 32;
  init_peep();
}

/*
 *   This routine is called when the compiler is closing down.
 */
PRIVATE void g_terminate P0(void) {
#ifdef VERBOSE
  c30_peep_report();
#endif
}

/*
 *   Returns the current register usage.
 */
PRIVATE REGUSAGE *g_regusage P0(TYP *tp) { return reg_usage; }

#ifdef MULTIPLE_PROCESSORS
#define MCC30_FUNCS (void *)&mcc30_funcs
#else
#define MCC30_FUNCS (void *)NULL
#endif /* MULTIPLE_PROCESSORS */

static OPTENUM yesnoopts[] = {{(const char *)"yes", OPT_YES}, {(const char *)"no", OPT_NO}, {(const char *)NULL, 0}};

static OPTENUM branchopts[] = {{(const char *)"none", OPT_NONE},
                               {(const char *)"low", OPT_LEVEL1},
                               {(const char *)"medium", OPT_LEVEL2},
                               {(const char *)"hard", OPT_LEVEL3},
                               {(const char *)NULL, 0}};

static OPTSET peepset[] = {{(const char *)"none", EMPTY_SET},
                           {(const char *)"flow", MEMBER(PEEP_FLOW)},
                           {(const char *)"pipeline", MEMBER(PEEP_PIPELINE)},
                           {(const char *)"3operand", MEMBER(PEEP_3OPERAND)},
                           {(const char *)"parallel", MEMBER(PEEP_PARALLEL)},
                           {(const char *)"more_parallel", MEMBER(PEEP_PARALLEL) | MEMBER(PEEP_PARALLEL_ALL)},
                           {(const char *)"remap", MEMBER(PEEP_REMAP)},
                           {(const char *)"minimal", MEMBER(PEEP_MINIMAL)},
                           {(const char *)"redundant", MEMBER(PEEP_REDUNDANT)},
                           {(const char *)"store", MEMBER(PEEP_STORE)},
                           {(const char *)"switch", MEMBER(PEEP_SWITCH)},
                           {(const char *)"hardremap", MEMBER(PEEP_HARD_REMAP)},
                           {(const char *)"forceswitchremap", MEMBER(PEEP_VERY_HARD_REMAP)},
                           {(const char *)"standard", PEEP_STANDARD},
                           {(const char *)"all", PEEP_ALL},
                           {(const char *)NULL, EMPTY_SET}};

static OPTENUM stackoptions[] = {{(const char *)"safest", OPT_SAFE},
                                 {(const char *)"minimum", OPT_MINIMUM},
                                 {(const char *)"average", OPT_AVERAGE},
                                 {(const char *)"maximum", OPT_MAXIMUM},
                                 {(const char *)NULL, 0}};

static OPTSET registeroptions[] = {
    {(const char *)"none", EMPTY_SET},

    {(const char *)"r0", MEMBER(REG_R0)},   {(const char *)"r1", MEMBER(REG_R1)},   {(const char *)"r2", MEMBER(REG_R2)},
    {(const char *)"r3", MEMBER(REG_R3)},   {(const char *)"r4", MEMBER(REG_R4)},   {(const char *)"r5", MEMBER(REG_R5)},
    {(const char *)"r6", MEMBER(REG_R6)},   {(const char *)"r7", MEMBER(REG_R7)},   {(const char *)"rn", MASK_REG_DATA},

    {(const char *)"ar0", MEMBER(REG_AR0)}, {(const char *)"ar1", MEMBER(REG_AR1)}, {(const char *)"ar2", MEMBER(REG_AR2)},
    {(const char *)"ar3", MEMBER(REG_AR3)}, {(const char *)"ar4", MEMBER(REG_AR4)}, {(const char *)"ar5", MEMBER(REG_AR5)},
    {(const char *)"ar6", MEMBER(REG_AR6)}, {(const char *)"ar7", MEMBER(REG_AR7)}, {(const char *)"arn", MASK_REG_ADDRESS},

    {(const char *)"dp", MEMBER(REG_DP)},   {(const char *)"ir0", MEMBER(REG_IR0)}, {(const char *)"ir1", MEMBER(REG_IR1)},
    {(const char *)"bk", MEMBER(REG_BK)},   {(const char *)"sp", MEMBER(REG_SP)},   {(const char *)"st", MEMBER(REG_ST)},
    {(const char *)"ie", MEMBER(REG_IE)},   {(const char *)"if", MEMBER(REG_IF)},   {(const char *)"iof", MEMBER(REG_IOF)},
    {(const char *)"rs", MEMBER(REG_RS)},   {(const char *)"re", MEMBER(REG_RE)},   {(const char *)"rc", MEMBER(REG_RC)},
    {(const char *)"all", MASK_REG_ALL},    {(const char *)NULL, EMPTY_SET}};

static OPTION opts[] = {{(const char *)"optbranch=", enumeration_option, {&opt_branches}, {&branchopts[0]}},
                        {(const char *)"delayed=", numeric_option, {&opt_delayed_branches}, {NULL}},
                        {(const char *)"mul32=", enumeration_option, {&opt_true_long}, {&yesnoopts[0]}},
                        {(const char *)"peep=", set_option, {&peep_option}, {&peepset[0]}},
                        {(const char *)"prefix=", string_option, {&external_prefix}, {NULL}},
                        {(const char *)"pseq=", string_option, {&opt_peep_sequence}, {NULL}},
                        {(const char *)"ramconst=", enumeration_option, {&opt_const_in_ram}, {&yesnoopts[0]}},
                        {(const char *)"reg=", enumeration_option, {&reg_option}, {&yesnoopts[0]}},
                        {(const char *)"shortfloat=", numeric_option, {&opt_shortfloat}, {NULL}},
                        {(const char *)"interrupt=", enumeration_option, {&interrupt_option}, {&yesnoopts[0]}},
                        {(const char *)"trap=", enumeration_option, {&opt_traps}, {&yesnoopts[0]}},
                        {(const char *)"forcedsave=", set_option, {&forced_save_mask}, {&registeroptions[0]}},
#ifdef DEBUG
                        {(const char *)"peeptest=", numeric_option, {&opt_peep_test}, {NULL}},
#endif
#ifdef STACK_CHECK
                        {(const char *)"stackcheck=", enumeration_option, {&stackcheck_option}, {&yesnoopts[0]}},
#endif /* STACK_CHECK */
                        {(const char *)"stackopt=", enumeration_option, {&stackopt_option}, {&stackoptions[0]}},
#ifdef TRANSLATE
                        {(const char *)"trans=", enumeration_option, {&trans_option}, {&yesnoopts[0]}},
#endif /* TRANSLATE */
#ifdef MULTIPLE_ASSEMBLERS
#ifdef TARGET_ROSSIN
                        {(const char *)"rosc30", chip_option, {&rosc30_funcs}, {MCC30_FUNCS}},
#endif /* TARGET_ROSSIN */
#else
#ifdef TARGET_ROSSIN
                         {(const char *)"rosc30", chip_option, {NULL}, {MCC30_FUNCS}},
#endif /* TARGET_ROSSIN */
#endif /* MULTIPLE_ASSEMBLERS */
                        {(const char *)NULL, NULL, {NULL}, {NULL}}};

OPTIONS optsc30 = {(const char *)"TI TMS320C30 ", opts};

#ifdef MULTIPLE_PROCESSORS
struct genfuncs mcc30_funcs = {g_expression, g_jtrue,     g_jfalse,     g_stack,      g_switch_table, g_switch_compare,
                               g_entry,      g_return,    g_epilogue,   g_label,      g_branch,
#ifdef DEBUGOPT
                               g_line,
#endif /*DEBUGOPT */
                               g_allocate,   g_preload,   g_flush,      g_auto_align, g_is_bigendian, g_is_ascending_stack,
                               g_order,      g_transform, g_initialize, g_terminate,  g_regusage,     &alignments_c30[0]};

#endif /* MULTIPLE_PROCESSORS */
#endif /* TMS320C30 */
